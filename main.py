#!/usr/bin/env python3
"""
Free LLM Driver - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ç„¡æ–™ã‚ªãƒ³ãƒ©ã‚¤ãƒ³LLM + Open Interpreterå®Ÿè£…

ä½¿ç”¨ä¾‹:
    python main.py --goal "Pythonã§ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"
    python main.py --interactive
    python main.py --status
"""

import asyncio
import argparse
import logging
import os
import sys
import yaml
from pathlib import Path
from typing import Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from src.llm.provider_manager import LLMProviderManager
from src.agent.orchestrator import LightweightOrchestrator
from src.utils.quota_tracker import QuotaTracker
from src.utils.auto_optimizer import AutoOptimizer
from src.core.neural_kernel import NeuralKernel
from dotenv import load_dotenv

class FreeLLMDriver:
    """Free LLM Driver ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self, config_dir: str = "config"):
        self.config_dir = config_dir
        self.config = {}
        self.llm_manager = None
        self.orchestrator = None
        self.quota_tracker = None
        self.optimizer = None
        self.neural_kernel = None
        
        # ãƒ­ã‚°è¨­å®š
        self._setup_logging()
        
        # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
        load_dotenv()
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs('logs', exist_ok=True)
    
    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler('logs/free_llm_driver.log', encoding='utf-8')
            ]
        )
        
        # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
        logging.getLogger('httpx').setLevel(logging.WARNING)
        logging.getLogger('openai').setLevel(logging.WARNING)
        logging.getLogger('google').setLevel(logging.WARNING)
    
    async def initialize(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            logging.info("ğŸš€ Free LLM Driver ã‚’åˆæœŸåŒ–ä¸­...")
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            if not self._load_config():
                return False
            
            # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            self.quota_tracker = QuotaTracker()
            self.llm_manager = LLMProviderManager(self.config)
            
            if not await self.llm_manager.initialize():
                logging.error("âŒ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—")
                return False
            
            # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
            orchestrator_config = self.config.get('optimization', {})
            self.orchestrator = LightweightOrchestrator(self.llm_manager, orchestrator_config)
            
            # æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
            self.optimizer = AutoOptimizer(self.quota_tracker)
            
            # Neural KernelåˆæœŸåŒ–ã¨èµ·å‹•
            self.neural_kernel = NeuralKernel()
            await self.neural_kernel.start_neural_kernel()
            logging.info("ğŸ§  Neural Kernel èµ·å‹•å®Œäº†")
            
            logging.info("âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            logging.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _load_config(self) -> bool:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
            providers_path = os.path.join(self.config_dir, 'providers.yaml')
            if os.path.exists(providers_path):
                with open(providers_path, 'r', encoding='utf-8') as f:
                    providers_config = yaml.safe_load(f)
                    self.config.update(providers_config)
                logging.info("âœ… ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’èª­ã¿è¾¼ã¿")
            else:
                logging.warning(f"âš ï¸ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {providers_path}")
            
            # åˆ¶é™è¨­å®š
            limits_path = os.path.join(self.config_dir, 'limits.yaml')
            if os.path.exists(limits_path):
                with open(limits_path, 'r', encoding='utf-8') as f:
                    limits_config = yaml.safe_load(f)
                    self.config.update(limits_config)
                logging.info("âœ… åˆ¶é™è¨­å®šã‚’èª­ã¿è¾¼ã¿")
            else:
                logging.warning(f"âš ï¸ åˆ¶é™è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {limits_path}")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def execute_goal(self, goal: str) -> None:
        """ç›®æ¨™å®Ÿè¡Œ"""
        try:
            logging.info(f"ğŸ¯ ç›®æ¨™å®Ÿè¡Œ: {goal}")
            
            # å®Ÿè¡Œå‰ã®æœ€é©åŒ–ãƒã‚§ãƒƒã‚¯
            recommendations = self.optimizer.generate_optimization_recommendations()
            if recommendations:
                logging.info("ğŸ’¡ æœ€é©åŒ–æ¨å¥¨äº‹é …ãŒã‚ã‚Šã¾ã™:")
                for rec in recommendations[:3]:  # ä¸Šä½3ã¤
                    logging.info(f"  - {rec.provider}: {rec.action} ({rec.priority})")
            
            # ç›®æ¨™å®Ÿè¡Œ
            result = await self.orchestrator.execute_goal(goal)
            
            # ä½¿ç”¨é‡è¨˜éŒ²
            for execution_result in result.results:
                self.quota_tracker.log_request(
                    provider=execution_result.provider_used or 'unknown',
                    task_type='goal_execution',
                    success=execution_result.status.value == 'completed',
                    response_time=execution_result.execution_time
                )
            
            # çµæœè¡¨ç¤º
            self._display_result(result)
            
        except Exception as e:
            logging.error(f"âŒ ç›®æ¨™å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    def _display_result(self, result) -> None:
        """çµæœè¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ¯ å®Ÿè¡Œçµæœ")
        print("="*60)
        
        print(f"ç›®æ¨™: {result.goal}")
        print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {result.total_tasks}")
        print(f"å®Œäº†ã‚¿ã‚¹ã‚¯: {result.completed_tasks}")
        print(f"å¤±æ•—ã‚¿ã‚¹ã‚¯: {result.failed_tasks}")
        print(f"å®Ÿè¡Œæ™‚é–“: {result.total_time:.1f}ç§’")
        print(f"æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
        
        if result.summary:
            print(f"\nã‚µãƒãƒªãƒ¼:\n{result.summary}")
        
        # è©³ç´°çµæœï¼ˆæˆåŠŸã—ãŸã‚‚ã®ã®ã¿ï¼‰
        successful_results = [r for r in result.results if r.status.value == 'completed']
        if successful_results:
            print(f"\nğŸ“‹ å®Ÿè¡Œçµæœè©³ç´° ({len(successful_results)}ä»¶):")
            for i, exec_result in enumerate(successful_results[:3], 1):  # æœ€å¤§3ä»¶è¡¨ç¤º
                print(f"\n{i}. ã‚¿ã‚¹ã‚¯ID: {exec_result.task_id}")
                output = exec_result.output[:200] + "..." if len(exec_result.output) > 200 else exec_result.output
                print(f"   å‡ºåŠ›: {output}")
        
        print("\n" + "="*60)
    
    async def run_interactive_mode(self) -> None:
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰"""
        print("ğŸš€ Free LLM Driver - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰")
        print("ã‚³ãƒãƒ³ãƒ‰: /help, /status, /quit")
        print("-" * 50)
        
        while True:
            try:
                user_input = input("\nğŸ’­ ç›®æ¨™ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
                
                if not user_input:
                    continue
                    
                # ã‚³ãƒãƒ³ãƒ‰å‡¦ç†
                if user_input.startswith('/'):
                    if user_input == '/quit' or user_input == '/exit':
                        print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                        break
                    elif user_input == '/help':
                        self._show_help()
                    elif user_input == '/status':
                        await self._show_status()
                    elif user_input == '/optimize':
                        await self._show_optimization()
                    elif user_input == '/neural':
                        await self._show_neural_status()
                    else:
                        print("â“ æœªçŸ¥ã®ã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚/help ã§ä½¿ç”¨å¯èƒ½ã‚³ãƒãƒ³ãƒ‰ã‚’ç¢ºèª")
                    continue
                
                # ç›®æ¨™å®Ÿè¡Œ
                await self.execute_goal(user_input)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
                break
            except Exception as e:
                logging.error(f"âŒ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _show_help(self) -> None:
        """ãƒ˜ãƒ«ãƒ—è¡¨ç¤º"""
        print("""
ğŸ“š Free LLM Driver ãƒ˜ãƒ«ãƒ—

ä½¿ç”¨å¯èƒ½ã‚³ãƒãƒ³ãƒ‰:
  /help      - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
  /status    - ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã‚’è¡¨ç¤º
  /optimize  - æœ€é©åŒ–çŠ¶æ³ã‚’è¡¨ç¤º
  /neural    - Neural KernelçŠ¶æ³ã‚’è¡¨ç¤º
  /quit      - çµ‚äº†

ä½¿ç”¨ä¾‹:
  ğŸ’­ Pythonã§ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ
  ğŸ’­ ãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ã®ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
  ğŸ’­ ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®è¦ç´„ã‚’ä½œæˆ
        """)
    
    async def _show_status(self) -> None:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º"""
        try:
            print("\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³")
            print("-" * 40)
            
            # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼çŠ¶æ³
            provider_status = self.llm_manager.get_provider_status()
            print("\nğŸ”Œ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼çŠ¶æ³:")
            for provider, status in provider_status.items():
                available = "âœ…" if status['available'] else "âŒ"
                print(f"  {provider}: {available} (ä»Šæ—¥: {status['requests_today']}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ)")
            
            # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼çµ±è¨ˆ
            orch_stats = self.orchestrator.get_orchestrator_stats()
            print(f"\nğŸ¯ å®Ÿè¡Œçµ±è¨ˆ:")
            print(f"  ç·ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: {orch_stats['total_workflows']}")
            print(f"  æˆåŠŸç‡: {orch_stats['success_rate']:.1f}%")
            print(f"  å¹³å‡å®Ÿè¡Œæ™‚é–“: {orch_stats['average_execution_time']:.1f}ç§’")
            
            # ä½¿ç”¨é‡ã‚µãƒãƒªãƒ¼
            usage_summary = self.quota_tracker.get_usage_summary()
            print(f"\nğŸ“ˆ ä½¿ç”¨é‡ã‚µãƒãƒªãƒ¼:")
            print(f"  ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {usage_summary['total_requests']}")
            
            if usage_summary['providers']:
                print("  ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥:")
                for provider, stats in usage_summary['providers'].items():
                    print(f"    {provider}: {stats['requests']}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (æˆåŠŸç‡: {stats['success_rate']:.1f}%)")
            
        except Exception as e:
            logging.error(f"âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _show_optimization(self) -> None:
        """æœ€é©åŒ–çŠ¶æ³è¡¨ç¤º"""
        try:
            print("\nğŸ”§ æœ€é©åŒ–çŠ¶æ³")
            print("-" * 40)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            analysis = self.optimizer.analyze_current_performance()
            health_emoji = "âœ…" if analysis['overall_health'] == 'good' else "âš ï¸" if analysis['overall_health'] == 'warning' else "âŒ"
            print(f"\n{health_emoji} ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“: {analysis['overall_health']}")
            
            # æ¨å¥¨äº‹é …
            recommendations = self.optimizer.generate_optimization_recommendations()
            if recommendations:
                print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
                for rec in recommendations[:5]:  # ä¸Šä½5ã¤
                    priority_emoji = "ğŸš¨" if rec.priority == "ç·Šæ€¥" else "âš ï¸" if rec.priority == "é«˜" else "ğŸ’¡"
                    print(f"  {priority_emoji} {rec.provider}: {rec.action}")
                    print(f"     ç†ç”±: {rec.reason}")
            
            # ä½¿ç”¨é‡äºˆæ¸¬
            forecast = self.optimizer.get_usage_forecast(7)
            if forecast:
                print("\nğŸ“Š 7æ—¥é–“ä½¿ç”¨é‡äºˆæ¸¬:")
                for provider, pred in forecast.items():
                    if pred:
                        usage_rate = pred['projected_usage_rate']
                        emoji = "ğŸš¨" if usage_rate >= 0.9 else "âš ï¸" if usage_rate >= 0.7 else "âœ…"
                        print(f"  {emoji} {provider}: {usage_rate*100:.1f}% ä½¿ç”¨äºˆæƒ³")
            
        except Exception as e:
            logging.error(f"âŒ æœ€é©åŒ–çŠ¶æ³è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _show_neural_status(self) -> None:
        """Neural KernelçŠ¶æ³è¡¨ç¤º"""
        try:
            print("\nğŸ§  Neural Kernel çŠ¶æ³")
            print("-" * 40)
            
            if not self.neural_kernel:
                print("âŒ Neural Kernel ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return
            
            # åŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—
            status = await self.neural_kernel.get_comprehensive_status()
            
            # Neural KernelåŸºæœ¬çµ±è¨ˆ
            neural_stats = status.get('neural_kernel', {})
            running_status = "ğŸŸ¢ ç¨¼åƒä¸­" if neural_stats.get('running') else "ğŸ”´ åœæ­¢ä¸­"
            print(f"\nã‚«ãƒ¼ãƒãƒ«çŠ¶æ…‹: {running_status}")
            
            uptime_seconds = neural_stats.get('uptime_seconds', 0)
            uptime_minutes = uptime_seconds / 60
            print(f"ç¨¼åƒæ™‚é–“: {uptime_minutes:.1f}åˆ†")
            print(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å›æ•°: {neural_stats.get('total_health_checks', 0)}")
            print(f"ç·Šæ€¥å¯¾å¿œå›æ•°: {neural_stats.get('emergency_activations', 0)}")
            print(f"ç¾åœ¨ã®çŠ¶æ…‹: {neural_stats.get('current_status', 'unknown')}")
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹
            system_health = status.get('system_health', {})
            health_status = system_health.get('status', 'unknown')
            health_emoji = "ğŸŸ¢" if health_status == 'healthy' else "ğŸŸ¡" if health_status == 'warning' else "ğŸ”´"
            print(f"\n{health_emoji} ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹: {health_status}")
            
            # ãƒã‚¤ã‚¿ãƒ«ã‚µã‚¤ãƒ³
            vital_signs = system_health.get('vital_signs', {})
            if vital_signs:
                print("\nğŸ“Š ãƒã‚¤ã‚¿ãƒ«ã‚µã‚¤ãƒ³:")
                for name, vs in vital_signs.items():
                    status_emoji = "ğŸŸ¢" if vs['status'] == 'healthy' else "ğŸŸ¡" if vs['status'] == 'warning' else "ğŸ”´"
                    print(f"  {status_emoji} {name}: {vs['value']:.1f}{vs['unit']} ({vs['status']})")
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆ
            alerts = system_health.get('alerts', [])
            if alerts:
                print("\nğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆ:")
                for alert in alerts:
                    print(f"  - {alert}")
            
            # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
            resources = status.get('resources', {})
            resource_warnings = resources.get('warnings', [])
            if resource_warnings:
                print("\nâš ï¸ ãƒªã‚½ãƒ¼ã‚¹è­¦å‘Š:")
                for warning in resource_warnings:
                    print(f"  - {warning}")
            else:
                print("\nâœ… ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡: æ­£å¸¸ç¯„å›²å†…")
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰
            trend = system_health.get('trend', {})
            if trend.get('trend'):
                trend_emoji = "ğŸ“ˆ" if trend['trend'] == 'improving' else "ğŸ“‰" if trend['trend'] == 'degrading' else "ğŸ“Š"
                print(f"\n{trend_emoji} ãƒˆãƒ¬ãƒ³ãƒ‰: {trend['trend']}")
            
        except Exception as e:
            logging.error(f"âŒ Neural KernelçŠ¶æ³è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    async def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        try:
            if self.neural_kernel:
                await self.neural_kernel.stop_neural_kernel()
                logging.info("ğŸ§  Neural Kernel åœæ­¢å®Œäº†")
        except Exception as e:
            logging.error(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='Free LLM Driver - ç„¡æ–™ã‚ªãƒ³ãƒ©ã‚¤ãƒ³LLM + Open Interpreter'
    )
    parser.add_argument('--goal', '-g', type=str, help='å®Ÿè¡Œã™ã‚‹ç›®æ¨™')
    parser.add_argument('--interactive', '-i', action='store_true', help='ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--status', '-s', action='store_true', help='ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³è¡¨ç¤º')
    parser.add_argument('--optimize', '-o', action='store_true', help='æœ€é©åŒ–çŠ¶æ³è¡¨ç¤º')
    parser.add_argument('--config', '-c', type=str, default='config', help='è¨­å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    app = FreeLLMDriver(config_dir=args.config)
    
    if not await app.initialize():
        logging.error("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
    
    try:
        if args.status:
            await app._show_status()
        elif args.optimize:
            await app._show_optimization()
        elif args.goal:
            await app.execute_goal(args.goal)
        elif args.interactive:
            await app.run_interactive_mode()
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
            print("ä½¿ç”¨æ–¹æ³•: python main.py --help")
            print("ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹ã«ã¯: python main.py -i")
            
    except KeyboardInterrupt:
        logging.info("ğŸ‘‹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logging.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
        if 'app' in locals():
            await app.cleanup()

if __name__ == "__main__":
    asyncio.run(main())