"""
Executive Controller System - å‰é ­å‰çš®è³ªã‚’æ¨¡å€£ã—ãŸé«˜æ¬¡èªçŸ¥åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
ä½œæ¥­è¨˜æ†¶ã€æ³¨æ„ç®¡ç†ã€ç«¶åˆè§£æ±ºã€ãƒ¡ã‚¿èªçŸ¥çš„ç›£è¦–æ©Ÿèƒ½ã‚’çµ±åˆ
"""

import asyncio
import logging
import heapq
import math
from typing import Dict, Any, List, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timedelta
from collections import defaultdict, deque
import json

class CognitiveLoadLevel(Enum):
    """èªçŸ¥è² è·ãƒ¬ãƒ™ãƒ«"""
    LOW = 1
    MODERATE = 2
    HIGH = 3
    OVERLOAD = 4

class AttentionType(Enum):
    """æ³¨æ„ã®ç¨®é¡"""
    FOCUSED = "focused"        # é›†ä¸­çš„æ³¨æ„
    DIVIDED = "divided"        # åˆ†å‰²æ³¨æ„
    SUSTAINED = "sustained"    # æŒç¶šçš„æ³¨æ„
    SELECTIVE = "selective"    # é¸æŠçš„æ³¨æ„

class DecisionStrategy(Enum):
    """æ„æ€æ±ºå®šæˆ¦ç•¥"""
    RATIONAL = "rational"      # åˆç†çš„åˆ†æ
    INTUITIVE = "intuitive"    # ç›´æ„Ÿçš„åˆ¤æ–­
    HYBRID = "hybrid"          # æ··åˆå‹
    EMOTIONAL = "emotional"    # æ„Ÿæƒ…ä¸»å°
    CONSERVATIVE = "conservative"  # ä¿å®ˆçš„

@dataclass
class CognitiveTask:
    """èªçŸ¥ã‚¿ã‚¹ã‚¯"""
    task_id: str
    description: str
    task_type: str
    urgency: float  # 0-1
    importance: float  # 0-1
    complexity: float  # 0-1
    required_attention: float  # 0-100
    emotional_weight: float  # 0-1
    deadline: Optional[datetime]
    dependencies: List[str]
    context: Dict[str, Any]

@dataclass
class AttentionResource:
    """æ³¨æ„ãƒªã‚½ãƒ¼ã‚¹"""
    total_capacity: float
    allocated: float
    available: float
    efficiency: float  # ç¾åœ¨ã®åŠ¹ç‡
    fatigue_level: float  # ç–²åŠ´åº¦

@dataclass
class ExecutiveDecision:
    """å®Ÿè¡Œæ±ºå®š"""
    decision_id: str
    chosen_strategy: DecisionStrategy
    task_sequence: List[str]
    resource_allocation: Dict[str, float]
    confidence: float
    rationale: str
    alternatives_considered: List[Dict[str, Any]]
    timestamp: datetime

class WorkingMemory:
    """ä½œæ¥­è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, capacity: int = 7):  # Miller's magic number Â±2
        self.capacity = capacity
        self.phonological_loop = deque(maxlen=capacity)  # è¨€èªæƒ…å ±
        self.visuospatial_sketchpad = deque(maxlen=capacity)  # è¦–ç©ºé–“æƒ…å ±
        self.episodic_buffer = deque(maxlen=capacity)  # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±
        self.central_executive_state = {}
        
        # ä½œæ¥­è¨˜æ†¶ã®çµ±è¨ˆ
        self.usage_stats = {
            'total_items_processed': 0,
            'current_load': 0,
            'peak_load': 0,
            'interference_events': 0
        }
    
    def add_item(self, item: Any, memory_type: str = "episodic") -> bool:
        """ä½œæ¥­è¨˜æ†¶ã¸ã®é …ç›®è¿½åŠ """
        try:
            current_time = datetime.now()
            memory_item = {
                'content': item,
                'timestamp': current_time,
                'access_count': 0,
                'importance': getattr(item, 'importance', 0.5)
            }
            
            if memory_type == "phonological":
                if len(self.phonological_loop) >= self.capacity:
                    self._handle_capacity_overflow("phonological")
                self.phonological_loop.append(memory_item)
                
            elif memory_type == "visuospatial":
                if len(self.visuospatial_sketchpad) >= self.capacity:
                    self._handle_capacity_overflow("visuospatial")
                self.visuospatial_sketchpad.append(memory_item)
                
            else:  # episodic
                if len(self.episodic_buffer) >= self.capacity:
                    self._handle_capacity_overflow("episodic")
                self.episodic_buffer.append(memory_item)
            
            self.usage_stats['total_items_processed'] += 1
            self._update_load_stats()
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ ä½œæ¥­è¨˜æ†¶è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def retrieve_item(self, query: str, memory_type: str = "episodic") -> Optional[Any]:
        """ä½œæ¥­è¨˜æ†¶ã‹ã‚‰ã®é …ç›®æ¤œç´¢"""
        try:
            target_buffer = self._get_buffer(memory_type)
            
            for item in reversed(target_buffer):  # æœ€æ–°ã‹ã‚‰æ¤œç´¢
                if self._matches_query(item['content'], query):
                    item['access_count'] += 1
                    return item['content']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ ä½œæ¥­è¨˜æ†¶æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_current_context(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ä½œæ¥­è¨˜æ†¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        return {
            'phonological_items': len(self.phonological_loop),
            'visuospatial_items': len(self.visuospatial_sketchpad),
            'episodic_items': len(self.episodic_buffer),
            'total_load': self.get_cognitive_load(),
            'efficiency': self._calculate_efficiency(),
            'executive_state': self.central_executive_state.copy()
        }
    
    def get_cognitive_load(self) -> float:
        """ç¾åœ¨ã®èªçŸ¥è² è·ã‚’è¨ˆç®—"""
        total_items = (
            len(self.phonological_loop) + 
            len(self.visuospatial_sketchpad) + 
            len(self.episodic_buffer)
        )
        return min(total_items / (self.capacity * 3), 1.0)
    
    def _get_buffer(self, memory_type: str):
        """ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã™ã‚‹ãƒãƒƒãƒ•ã‚¡ã‚’å–å¾—"""
        if memory_type == "phonological":
            return self.phonological_loop
        elif memory_type == "visuospatial":
            return self.visuospatial_sketchpad
        else:
            return self.episodic_buffer
    
    def _handle_capacity_overflow(self, memory_type: str):
        """å®¹é‡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ™‚ã®å‡¦ç†"""
        self.usage_stats['interference_events'] += 1
        # LRU (Least Recently Used) ãƒ™ãƒ¼ã‚¹ã§å¤ã„é …ç›®ã‚’å‰Šé™¤
        # dequeã®æ€§è³ªä¸Šã€è‡ªå‹•çš„ã«å¤ã„é …ç›®ãŒå‰Šé™¤ã•ã‚Œã‚‹
    
    def _matches_query(self, content: Any, query: str) -> bool:
        """ã‚¯ã‚¨ãƒªã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒãƒãƒ³ã‚°"""
        content_str = str(content).lower()
        return query.lower() in content_str
    
    def _calculate_efficiency(self) -> float:
        """ä½œæ¥­è¨˜æ†¶ã®åŠ¹ç‡ã‚’è¨ˆç®—"""
        load = self.get_cognitive_load()
        # é©åº¦ãªè² è·ã§åŠ¹ç‡ãŒæœ€å¤§ã«ãªã‚‹é€†Uå­—ã‚«ãƒ¼ãƒ–
        optimal_load = 0.6
        if load <= optimal_load:
            return load / optimal_load
        else:
            return max(0.1, 1.0 - (load - optimal_load) / (1.0 - optimal_load))
    
    def _update_load_stats(self):
        """è² è·çµ±è¨ˆã®æ›´æ–°"""
        current_load = self.get_cognitive_load()
        self.usage_stats['current_load'] = current_load
        self.usage_stats['peak_load'] = max(self.usage_stats['peak_load'], current_load)

class AttentionManager:
    """æ³¨æ„ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, total_attention_capacity: float = 100.0):
        self.attention_resource = AttentionResource(
            total_capacity=total_attention_capacity,
            allocated=0.0,
            available=total_attention_capacity,
            efficiency=1.0,
            fatigue_level=0.0
        )
        
        self.active_tasks: Dict[str, CognitiveTask] = {}
        self.priority_queue = []  # heapqã‚’ä½¿ç”¨
        self.attention_history = deque(maxlen=1000)
        
        # æ³¨æ„ã®ã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        self.attention_performance = {
            AttentionType.FOCUSED: 1.0,
            AttentionType.DIVIDED: 0.7,
            AttentionType.SUSTAINED: 0.8,
            AttentionType.SELECTIVE: 0.9
        }
    
    async def allocate_attention(self, tasks: List[CognitiveTask]) -> Dict[str, float]:
        """æ³¨æ„ãƒªã‚½ãƒ¼ã‚¹ã®å‹•çš„é…åˆ†"""
        try:
            allocations = {}
            
            # ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦è¨ˆç®—
            prioritized_tasks = []
            for task in tasks:
                priority = await self._calculate_priority(task)
                heapq.heappush(prioritized_tasks, (-priority, task))  # æœ€å¤§ãƒ’ãƒ¼ãƒ—
            
            # ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
            remaining_attention = self.attention_resource.available
            
            while prioritized_tasks and remaining_attention > 0:
                neg_priority, task = heapq.heappop(prioritized_tasks)
                priority = -neg_priority
                
                # å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ã¨åˆ©ç”¨å¯èƒ½ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¯”è¼ƒ
                required = min(task.required_attention, remaining_attention)
                
                # æ³¨æ„ã‚¿ã‚¤ãƒ—ã®æ±ºå®š
                attention_type = self._determine_attention_type(task, len(self.active_tasks))
                efficiency = self.attention_performance[attention_type]
                
                # åŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸå®ŸåŠ¹é…åˆ†
                effective_allocation = required * efficiency
                allocations[task.task_id] = effective_allocation
                
                # ãƒªã‚½ãƒ¼ã‚¹æ›´æ–°
                remaining_attention -= required
                self.active_tasks[task.task_id] = task
                
                # å±¥æ­´è¨˜éŒ²
                self.attention_history.append({
                    'task_id': task.task_id,
                    'allocated': effective_allocation,
                    'attention_type': attention_type.value,
                    'timestamp': datetime.now()
                })
            
            # ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹æ›´æ–°
            self._update_attention_resource(allocations)
            
            logging.debug(f"ğŸ¯ æ³¨æ„é…åˆ†å®Œäº†: {len(allocations)}ã‚¿ã‚¹ã‚¯ã«é…åˆ†")
            return allocations
            
        except Exception as e:
            logging.error(f"âŒ æ³¨æ„é…åˆ†ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    async def _calculate_priority(self, task: CognitiveTask) -> float:
        """ã‚¿ã‚¹ã‚¯å„ªå…ˆåº¦ã®è¨ˆç®—"""
        # ã‚¢ã‚¤ã‚¼ãƒ³ãƒãƒ¯ãƒ¼ãƒãƒˆãƒªã‚¯ã‚¹ + æ„Ÿæƒ…çš„é‡ã¿
        urgency_importance = task.urgency * task.importance
        
        # ç· åˆ‡ã«ã‚ˆã‚‹ç·Šæ€¥åº¦èª¿æ•´
        deadline_pressure = 0.0
        if task.deadline:
            time_to_deadline = (task.deadline - datetime.now()).total_seconds()
            if time_to_deadline > 0:
                # æ™‚é–“ãŒå°‘ãªã„ã»ã©å„ªå…ˆåº¦UP
                deadline_pressure = max(0, 1.0 - time_to_deadline / (24 * 3600))  # 1æ—¥ã‚’åŸºæº–
        
        # æ„Ÿæƒ…çš„é‡ã¿ã®è€ƒæ…®
        emotional_boost = task.emotional_weight * 0.3
        
        # è¤‡é›‘æ€§ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯æ—©ã‚ã«ç€æ‰‹ï¼‰
        complexity_factor = task.complexity * 0.2
        
        # ç·åˆå„ªå…ˆåº¦
        total_priority = (
            urgency_importance * 0.5 +
            deadline_pressure * 0.3 +
            emotional_boost +
            complexity_factor
        )
        
        return min(total_priority, 1.0)
    
    def _determine_attention_type(self, task: CognitiveTask, active_task_count: int) -> AttentionType:
        """æ³¨æ„ã‚¿ã‚¤ãƒ—ã®æ±ºå®š"""
        if active_task_count == 0:
            return AttentionType.FOCUSED
        elif active_task_count == 1:
            return AttentionType.SELECTIVE
        elif task.complexity > 0.7:
            return AttentionType.SUSTAINED
        else:
            return AttentionType.DIVIDED
    
    def _update_attention_resource(self, allocations: Dict[str, float]):
        """æ³¨æ„ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹ã®æ›´æ–°"""
        total_allocated = sum(allocations.values())
        self.attention_resource.allocated = total_allocated
        self.attention_resource.available = self.attention_resource.total_capacity - total_allocated
        
        # ç–²åŠ´åº¦ã®æ›´æ–°ï¼ˆé«˜è² è·ã§ç–²åŠ´è“„ç©ï¼‰
        load_ratio = total_allocated / self.attention_resource.total_capacity
        if load_ratio > 0.8:
            self.attention_resource.fatigue_level += 0.1
        elif load_ratio < 0.3:
            self.attention_resource.fatigue_level = max(0, self.attention_resource.fatigue_level - 0.05)
        
        # åŠ¹ç‡ã®è¨ˆç®—ï¼ˆç–²åŠ´åº¦ã®å½±éŸ¿ï¼‰
        self.attention_resource.efficiency = max(0.1, 1.0 - self.attention_resource.fatigue_level)
    
    async def release_attention(self, task_id: str):
        """æ³¨æ„ãƒªã‚½ãƒ¼ã‚¹ã®è§£æ”¾"""
        if task_id in self.active_tasks:
            task = self.active_tasks[task_id]
            released_amount = task.required_attention
            
            del self.active_tasks[task_id]
            self.attention_resource.available += released_amount
            self.attention_resource.allocated -= released_amount
            
            logging.debug(f"ğŸ”“ æ³¨æ„è§£æ”¾: {task_id} -> {released_amount}ãƒªã‚½ãƒ¼ã‚¹")
    
    def get_attention_statistics(self) -> Dict[str, Any]:
        """æ³¨æ„ç®¡ç†çµ±è¨ˆ"""
        return {
            'total_capacity': self.attention_resource.total_capacity,
            'allocated': self.attention_resource.allocated,
            'available': self.attention_resource.available,
            'efficiency': self.attention_resource.efficiency,
            'fatigue_level': self.attention_resource.fatigue_level,
            'active_tasks': len(self.active_tasks),
            'attention_history_size': len(self.attention_history)
        }

class ConflictResolver:
    """ç«¶åˆè§£æ±ºã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.resolution_strategies = {
            'resource_conflict': self._resolve_resource_conflict,
            'priority_conflict': self._resolve_priority_conflict,
            'temporal_conflict': self._resolve_temporal_conflict,
            'strategy_conflict': self._resolve_strategy_conflict
        }
        
        self.conflict_history = deque(maxlen=500)
        
    async def resolve_conflict(self, conflicting_options: List[Dict[str, Any]], 
                             context: Dict[str, Any]) -> Dict[str, Any]:
        """ç«¶åˆã®è§£æ±º"""
        try:
            # ç«¶åˆã®ç¨®é¡ã‚’ç‰¹å®š
            conflict_type = self._identify_conflict_type(conflicting_options, context)
            
            # å¯¾å¿œã™ã‚‹è§£æ±ºæˆ¦ç•¥ã‚’å®Ÿè¡Œ
            resolution_strategy = self.resolution_strategies.get(
                conflict_type, self._resolve_generic_conflict
            )
            
            resolved_decision = await resolution_strategy(conflicting_options, context)
            
            # ç«¶åˆå±¥æ­´ã«è¨˜éŒ²
            conflict_record = {
                'conflict_type': conflict_type,
                'options_count': len(conflicting_options),
                'resolution': resolved_decision,
                'timestamp': datetime.now()
            }
            self.conflict_history.append(conflict_record)
            
            logging.info(f"âš–ï¸ ç«¶åˆè§£æ±º: {conflict_type} -> {resolved_decision.get('strategy', 'unknown')}")
            return resolved_decision
            
        except Exception as e:
            logging.error(f"âŒ ç«¶åˆè§£æ±ºã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
            return conflicting_options[0] if conflicting_options else {}
    
    def _identify_conflict_type(self, options: List[Dict[str, Any]], 
                               context: Dict[str, Any]) -> str:
        """ç«¶åˆã‚¿ã‚¤ãƒ—ã®ç‰¹å®š"""
        # ãƒªã‚½ãƒ¼ã‚¹ç«¶åˆã®æ¤œå‡º
        total_required_resources = sum(
            option.get('required_resources', 0) for option in options
        )
        available_resources = context.get('available_resources', 100)
        
        if total_required_resources > available_resources:
            return 'resource_conflict'
        
        # å„ªå…ˆåº¦ç«¶åˆã®æ¤œå‡º
        priorities = [option.get('priority', 0) for option in options]
        if len(set(priorities)) < len(priorities) * 0.5:  # åŠæ•°ä»¥ä¸ŠãŒåŒã˜å„ªå…ˆåº¦
            return 'priority_conflict'
        
        # æ™‚é–“çš„ç«¶åˆã®æ¤œå‡º
        deadlines = [option.get('deadline') for option in options if option.get('deadline')]
        if len(deadlines) > 1:
            return 'temporal_conflict'
        
        # æˆ¦ç•¥ç«¶åˆã®æ¤œå‡º
        strategies = [option.get('strategy') for option in options]
        if len(set(strategies)) == len(strategies):  # å…¨ã¦ç•°ãªã‚‹æˆ¦ç•¥
            return 'strategy_conflict'
        
        return 'generic_conflict'
    
    async def _resolve_resource_conflict(self, options: List[Dict[str, Any]], 
                                       context: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªã‚½ãƒ¼ã‚¹ç«¶åˆã®è§£æ±º"""
        # åŠ¹ç‡æ€§ã§ã‚½ãƒ¼ãƒˆ
        efficiency_sorted = sorted(
            options, 
            key=lambda x: x.get('expected_value', 0) / max(x.get('required_resources', 1), 1),
            reverse=True
        )
        return efficiency_sorted[0]
    
    async def _resolve_priority_conflict(self, options: List[Dict[str, Any]], 
                                       context: Dict[str, Any]) -> Dict[str, Any]:
        """å„ªå…ˆåº¦ç«¶åˆã®è§£æ±º"""
        # ã‚»ã‚«ãƒ³ãƒ€ãƒªåŸºæº–ï¼ˆæ„Ÿæƒ…çš„é‡ã¿ã€è¤‡é›‘æ€§ãªã©ï¼‰ã§åˆ¤å®š
        secondary_sorted = sorted(
            options,
            key=lambda x: (
                x.get('emotional_weight', 0) * 0.4 +
                x.get('urgency', 0) * 0.6
            ),
            reverse=True
        )
        return secondary_sorted[0]
    
    async def _resolve_temporal_conflict(self, options: List[Dict[str, Any]], 
                                       context: Dict[str, Any]) -> Dict[str, Any]:
        """æ™‚é–“çš„ç«¶åˆã®è§£æ±º"""
        # ç· åˆ‡ãŒæœ€ã‚‚è¿‘ã„ã‚‚ã®ã‚’å„ªå…ˆ
        deadline_sorted = sorted(
            options,
            key=lambda x: x.get('deadline', datetime.max)
        )
        return deadline_sorted[0]
    
    async def _resolve_strategy_conflict(self, options: List[Dict[str, Any]], 
                                       context: Dict[str, Any]) -> Dict[str, Any]:
        """æˆ¦ç•¥ç«¶åˆã®è§£æ±º"""
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æœ€ã‚‚é©ã—ãŸæˆ¦ç•¥ã‚’é¸æŠ
        system_state = context.get('system_state', {})
        
        if system_state.get('stress_level', 0) > 0.7:
            # é«˜ã‚¹ãƒˆãƒ¬ã‚¹æ™‚ã¯ä¿å®ˆçš„æˆ¦ç•¥ã‚’å„ªå…ˆ
            for option in options:
                if option.get('strategy') == 'conservative':
                    return option
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯åˆç†çš„æˆ¦ç•¥
        for option in options:
            if option.get('strategy') == 'rational':
                return option
        
        return options[0]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    async def _resolve_generic_conflict(self, options: List[Dict[str, Any]], 
                                      context: Dict[str, Any]) -> Dict[str, Any]:
        """æ±ç”¨çš„ç«¶åˆè§£æ±º"""
        # å¤šåŸºæº–æ„æ€æ±ºå®šåˆ†æï¼ˆMCDAï¼‰
        weights = {
            'priority': 0.3,
            'expected_value': 0.25,
            'confidence': 0.2,
            'emotional_weight': 0.15,
            'efficiency': 0.1
        }
        
        scored_options = []
        for option in options:
            score = sum(
                option.get(criterion, 0) * weight
                for criterion, weight in weights.items()
            )
            scored_options.append((score, option))
        
        scored_options.sort(reverse=True)
        return scored_options[0][1]

class MetaCognitiveMonitor:
    """ãƒ¡ã‚¿èªçŸ¥ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.monitoring_active = False
        self.performance_metrics = {
            'decision_accuracy': deque(maxlen=100),
            'execution_efficiency': deque(maxlen=100),
            'learning_rate': deque(maxlen=100),
            'error_rate': deque(maxlen=100)
        }
        
        self.metacognitive_beliefs = {
            'confidence_calibration': 0.5,  # ä¿¡é ¼åº¦ã®æ ¡æ­£
            'strategy_effectiveness': defaultdict(float),
            'task_difficulty_estimation': defaultdict(float)
        }
        
        self.monitoring_history = deque(maxlen=1000)
    
    async def start_monitoring(self, decision: ExecutiveDecision):
        """ãƒ¡ã‚¿èªçŸ¥ç›£è¦–ã®é–‹å§‹"""
        try:
            self.monitoring_active = True
            
            monitoring_context = {
                'decision_id': decision.decision_id,
                'strategy': decision.chosen_strategy.value,
                'confidence': decision.confidence,
                'start_time': datetime.now(),
                'expected_difficulty': self._estimate_task_difficulty(decision)
            }
            
            self.monitoring_history.append(monitoring_context)
            
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ç›£è¦–ã‚’é–‹å§‹
            monitoring_task = asyncio.create_task(
                self._continuous_monitoring(monitoring_context)
            )
            
            logging.debug(f"ğŸ” ãƒ¡ã‚¿èªçŸ¥ç›£è¦–é–‹å§‹: {decision.decision_id}")
            return monitoring_task
            
        except Exception as e:
            logging.error(f"âŒ ãƒ¡ã‚¿èªçŸ¥ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _continuous_monitoring(self, context: Dict[str, Any]):
        """ç¶™ç¶šçš„ãªç›£è¦–ãƒ—ãƒ­ã‚»ã‚¹"""
        try:
            start_time = context['start_time']
            
            while self.monitoring_active:
                current_time = datetime.now()
                elapsed_time = (current_time - start_time).total_seconds()
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
                performance_assessment = await self._assess_current_performance(context)
                
                # å¿…è¦ã«å¿œã˜ã¦ä»‹å…¥
                if performance_assessment['needs_intervention']:
                    await self._metacognitive_intervention(context, performance_assessment)
                
                # ä¿¡å¿µã®æ›´æ–°
                self._update_metacognitive_beliefs(context, performance_assessment)
                
                # 1ç§’é–“éš”ã§ç›£è¦–
                await asyncio.sleep(1.0)
                
                # æœ€å¤§ç›£è¦–æ™‚é–“ï¼ˆ5åˆ†ï¼‰
                if elapsed_time > 300:
                    break
                    
        except asyncio.CancelledError:
            logging.debug("ğŸ” ãƒ¡ã‚¿èªçŸ¥ç›£è¦–ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            logging.error(f"âŒ ãƒ¡ã‚¿èªçŸ¥ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _assess_current_performance(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡"""
        try:
            current_time = datetime.now()
            elapsed_time = (current_time - context['start_time']).total_seconds()
            
            # é€²æ—è©•ä¾¡
            expected_progress = elapsed_time / context.get('estimated_duration', 60)
            # å®Ÿéš›ã®é€²æ—ã¯å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ã“ã“ã§ã¯ç°¡ç•¥åŒ–
            actual_progress = min(elapsed_time / 60, 1.0)  # ç°¡ç•¥åŒ–ã•ã‚ŒãŸé€²æ—
            
            progress_deviation = abs(expected_progress - actual_progress)
            
            # ä»‹å…¥ãŒå¿…è¦ã‹ã®åˆ¤å®š
            needs_intervention = (
                progress_deviation > 0.3 or  # 30%ä»¥ä¸Šã®é…ã‚Œ
                elapsed_time > context.get('estimated_duration', 60) * 1.5  # 1.5å€ã®æ™‚é–“è¶…é
            )
            
            return {
                'progress_deviation': progress_deviation,
                'needs_intervention': needs_intervention,
                'confidence_drift': context['confidence'] - 0.5,  # ç°¡ç•¥åŒ–
                'elapsed_time': elapsed_time
            }
            
        except Exception as e:
            logging.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {'needs_intervention': False}
    
    async def _metacognitive_intervention(self, context: Dict[str, Any], 
                                        assessment: Dict[str, Any]):
        """ãƒ¡ã‚¿èªçŸ¥çš„ä»‹å…¥"""
        try:
            intervention_type = "unknown"
            
            if assessment['progress_deviation'] > 0.3:
                intervention_type = "progress_adjustment"
                # é€²æ—èª¿æ•´ã®ææ¡ˆ
                logging.warning(f"ğŸš¨ é€²æ—é…å»¶æ¤œå‡º: {context['decision_id']}")
                
            elif assessment.get('confidence_drift', 0) < -0.2:
                intervention_type = "confidence_restoration"
                # ä¿¡é ¼åº¦å›å¾©ã®ææ¡ˆ
                logging.warning(f"ğŸš¨ ä¿¡é ¼åº¦ä½ä¸‹æ¤œå‡º: {context['decision_id']}")
            
            # ä»‹å…¥å±¥æ­´ã«è¨˜éŒ²
            intervention_record = {
                'context': context,
                'intervention_type': intervention_type,
                'assessment': assessment,
                'timestamp': datetime.now()
            }
            
            # å®Ÿéš›ã®ä»‹å…¥ã¯ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å§”è­²
            logging.info(f"ğŸ”§ ãƒ¡ã‚¿èªçŸ¥ä»‹å…¥: {intervention_type}")
            
        except Exception as e:
            logging.error(f"âŒ ãƒ¡ã‚¿èªçŸ¥ä»‹å…¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _estimate_task_difficulty(self, decision: ExecutiveDecision) -> float:
        """ã‚¿ã‚¹ã‚¯é›£æ˜“åº¦ã®æ¨å®š"""
        # æˆ¦ç•¥ã®è¤‡é›‘æ€§ã€ã‚¿ã‚¹ã‚¯æ•°ã€ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚ãªã©ã‹ã‚‰æ¨å®š
        base_difficulty = len(decision.task_sequence) / 10.0
        strategy_complexity = {
            DecisionStrategy.RATIONAL: 0.3,
            DecisionStrategy.INTUITIVE: 0.1,
            DecisionStrategy.HYBRID: 0.5,
            DecisionStrategy.EMOTIONAL: 0.2,
            DecisionStrategy.CONSERVATIVE: 0.4
        }
        
        strategy_factor = strategy_complexity.get(decision.chosen_strategy, 0.3)
        confidence_factor = 1.0 - decision.confidence
        
        estimated_difficulty = min(base_difficulty + strategy_factor + confidence_factor, 1.0)
        return estimated_difficulty
    
    def _update_metacognitive_beliefs(self, context: Dict[str, Any], 
                                    assessment: Dict[str, Any]):
        """ãƒ¡ã‚¿èªçŸ¥çš„ä¿¡å¿µã®æ›´æ–°"""
        strategy = context['strategy']
        
        # æˆ¦ç•¥åŠ¹æœæ€§ã®æ›´æ–°
        if not assessment['needs_intervention']:
            self.metacognitive_beliefs['strategy_effectiveness'][strategy] += 0.1
        else:
            self.metacognitive_beliefs['strategy_effectiveness'][strategy] -= 0.05
        
        # ä¿¡é ¼åº¦æ ¡æ­£ã®æ›´æ–°
        confidence_error = abs(context['confidence'] - assessment.get('actual_performance', 0.5))
        learning_rate = 0.05
        self.metacognitive_beliefs['confidence_calibration'] += learning_rate * confidence_error
    
    def stop_monitoring(self):
        """ç›£è¦–ã®åœæ­¢"""
        self.monitoring_active = False
    
    def get_metacognitive_statistics(self) -> Dict[str, Any]:
        """ãƒ¡ã‚¿èªçŸ¥çµ±è¨ˆ"""
        return {
            'monitoring_active': self.monitoring_active,
            'confidence_calibration': self.metacognitive_beliefs['confidence_calibration'],
            'strategy_effectiveness': dict(self.metacognitive_beliefs['strategy_effectiveness']),
            'monitoring_history_size': len(self.monitoring_history),
            'performance_metrics': {
                metric: len(values) for metric, values in self.performance_metrics.items()
            }
        }

class ExecutiveController:
    """é«˜æ¬¡èªçŸ¥åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ"""
    
    def __init__(self):
        self.working_memory = WorkingMemory()
        self.attention_manager = AttentionManager()
        self.conflict_resolver = ConflictResolver()
        self.meta_cognition = MetaCognitiveMonitor()
        
        # æ„æ€æ±ºå®šå±¥æ­´
        self.decision_history = deque(maxlen=1000)
        
        # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.strategy_performance = defaultdict(list)
        
    async def executive_decision(self, task_options: List[CognitiveTask], 
                               context: Dict[str, Any]) -> ExecutiveDecision:
        """é«˜æ¬¡ã®å®Ÿè¡Œæ±ºå®šãƒ—ãƒ­ã‚»ã‚¹"""
        try:
            decision_start_time = datetime.now()
            
            # 1. ä½œæ¥­è¨˜æ†¶ã¸ã®æƒ…å ±ãƒ­ãƒ¼ãƒ‰
            for task in task_options:
                self.working_memory.add_item(task, "episodic")
            
            # 2. æ³¨æ„ãƒªã‚½ãƒ¼ã‚¹ã®è©•ä¾¡
            attention_allocations = await self.attention_manager.allocate_attention(task_options)
            
            # 3. è¤‡æ•°è©•ä¾¡è»¸ã§ã®åˆ†æ
            evaluations = await asyncio.gather(
                self._rational_analysis(task_options, context),
                self._intuitive_analysis(task_options, context),
                self._emotional_analysis(task_options, context)
            )
            
            # 4. ç«¶åˆæ¤œå‡ºã¨è§£æ±º
            if self._detect_evaluation_conflicts(evaluations):
                resolved_evaluation = await self.conflict_resolver.resolve_conflict(
                    evaluations, context
                )
            else:
                resolved_evaluation = self._integrate_evaluations(evaluations)
            
            # 5. æœ€çµ‚æ±ºå®šã®å½¢æˆ
            executive_decision = self._form_executive_decision(
                resolved_evaluation, attention_allocations, context
            )
            
            # 6. ãƒ¡ã‚¿èªçŸ¥ç›£è¦–ã®é–‹å§‹
            monitoring_task = await self.meta_cognition.start_monitoring(executive_decision)
            
            # 7. æ±ºå®šå±¥æ­´ã¸ã®è¨˜éŒ²
            self.decision_history.append(executive_decision)
            
            execution_time = (datetime.now() - decision_start_time).total_seconds()
            logging.info(f"ğŸ§  å®Ÿè¡Œæ±ºå®šå®Œäº†: {executive_decision.decision_id} "
                        f"({execution_time:.2f}ç§’, æˆ¦ç•¥: {executive_decision.chosen_strategy.value})")
            
            return executive_decision
            
        except Exception as e:
            logging.error(f"âŒ å®Ÿè¡Œæ±ºå®šã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ±ºå®š
            return self._create_fallback_decision(task_options)
    
    async def _rational_analysis(self, tasks: List[CognitiveTask], 
                               context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆç†çš„åˆ†æ"""
        try:
            # æœŸå¾…å€¤ç†è«–ã«åŸºã¥ãåˆ†æ
            task_scores = []
            
            for task in tasks:
                # åˆ©ç›Š Ã— æˆåŠŸç¢ºç‡ - ã‚³ã‚¹ãƒˆ Ã— å¤±æ•—ç¢ºç‡
                estimated_success_prob = 1.0 - task.complexity * 0.3
                expected_benefit = task.importance * estimated_success_prob
                estimated_cost = task.required_attention / 100.0
                
                utility_score = expected_benefit - estimated_cost
                task_scores.append((utility_score, task))
            
            # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ
            task_scores.sort(reverse=True)
            best_task = task_scores[0][1] if task_scores else tasks[0]
            
            return {
                'strategy': DecisionStrategy.RATIONAL,
                'recommended_task': best_task,
                'confidence': 0.8,
                'rationale': 'Expected utility maximization',
                'evaluation_details': task_scores[:3]
            }
            
        except Exception as e:
            logging.error(f"âŒ åˆç†çš„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {'strategy': DecisionStrategy.RATIONAL, 'confidence': 0.1}
    
    async def _intuitive_analysis(self, tasks: List[CognitiveTask], 
                                context: Dict[str, Any]) -> Dict[str, Any]:
        """ç›´æ„Ÿçš„åˆ†æ"""
        try:
            # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã®åˆ¤æ–­
            intuitive_scores = []
            
            for task in tasks:
                # èªè­˜ã—ã‚„ã™ã•ï¼ˆavailability heuristicï¼‰
                familiarity = 1.0 - task.complexity
                
                # ä»£è¡¨æ€§ï¼ˆrepresentativeness heuristicï¼‰
                typical_pattern = 0.7 if task.task_type in ['simple', 'qa'] else 0.5
                
                # ã‚¢ãƒ³ã‚«ãƒªãƒ³ã‚°åŠ¹æœ
                anchor_adjustment = task.urgency * 0.8
                
                intuitive_score = (familiarity + typical_pattern + anchor_adjustment) / 3.0
                intuitive_scores.append((intuitive_score, task))
            
            intuitive_scores.sort(reverse=True)
            best_task = intuitive_scores[0][1] if intuitive_scores else tasks[0]
            
            return {
                'strategy': DecisionStrategy.INTUITIVE,
                'recommended_task': best_task,
                'confidence': 0.6,
                'rationale': 'Heuristic-based fast judgment',
                'evaluation_details': intuitive_scores[:3]
            }
            
        except Exception as e:
            logging.error(f"âŒ ç›´æ„Ÿçš„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {'strategy': DecisionStrategy.INTUITIVE, 'confidence': 0.1}
    
    async def _emotional_analysis(self, tasks: List[CognitiveTask], 
                                context: Dict[str, Any]) -> Dict[str, Any]:
        """æ„Ÿæƒ…çš„åˆ†æ"""
        try:
            emotional_scores = []
            
            for task in tasks:
                # æ„Ÿæƒ…çš„é‡ã¿ã«åŸºã¥ãè©•ä¾¡
                emotional_appeal = task.emotional_weight
                
                # ã‚¹ãƒˆãƒ¬ã‚¹è»½æ¸›åŠ¹æœ
                stress_relief = 1.0 - task.complexity if task.task_type == 'creative' else 0.3
                
                # é”æˆæ„Ÿã®äºˆæ¸¬
                achievement_feeling = task.importance * 0.8
                
                emotional_score = (emotional_appeal + stress_relief + achievement_feeling) / 3.0
                emotional_scores.append((emotional_score, task))
            
            emotional_scores.sort(reverse=True)
            best_task = emotional_scores[0][1] if emotional_scores else tasks[0]
            
            return {
                'strategy': DecisionStrategy.EMOTIONAL,
                'recommended_task': best_task,
                'confidence': 0.7,
                'rationale': 'Emotion-driven selection',
                'evaluation_details': emotional_scores[:3]
            }
            
        except Exception as e:
            logging.error(f"âŒ æ„Ÿæƒ…çš„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {'strategy': DecisionStrategy.EMOTIONAL, 'confidence': 0.1}
    
    def _detect_evaluation_conflicts(self, evaluations: List[Dict[str, Any]]) -> bool:
        """è©•ä¾¡é–“ã®ç«¶åˆæ¤œå‡º"""
        recommended_tasks = [
            eval_result.get('recommended_task') 
            for eval_result in evaluations 
            if eval_result.get('recommended_task')
        ]
        
        # ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç«¶åˆ
        unique_recommendations = set(
            task.task_id for task in recommended_tasks if task
        )
        
        return len(unique_recommendations) > 1
    
    def _integrate_evaluations(self, evaluations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è©•ä¾¡ã®çµ±åˆ"""
        # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘å¹³å‡
        total_confidence = sum(eval_result.get('confidence', 0) for eval_result in evaluations)
        
        if total_confidence == 0:
            return evaluations[0]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„è©•ä¾¡ã‚’æ¡ç”¨
        best_evaluation = max(evaluations, key=lambda x: x.get('confidence', 0))
        best_evaluation['strategy'] = DecisionStrategy.HYBRID
        best_evaluation['rationale'] = 'Integrated multi-perspective analysis'
        
        return best_evaluation
    
    def _form_executive_decision(self, evaluation: Dict[str, Any], 
                               attention_allocations: Dict[str, float], 
                               context: Dict[str, Any]) -> ExecutiveDecision:
        """å®Ÿè¡Œæ±ºå®šã®å½¢æˆ"""
        decision_id = f"exec_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        recommended_task = evaluation.get('recommended_task')
        task_sequence = [recommended_task.task_id] if recommended_task else []
        
        decision = ExecutiveDecision(
            decision_id=decision_id,
            chosen_strategy=evaluation.get('strategy', DecisionStrategy.RATIONAL),
            task_sequence=task_sequence,
            resource_allocation=attention_allocations,
            confidence=evaluation.get('confidence', 0.5),
            rationale=evaluation.get('rationale', 'Default decision'),
            alternatives_considered=evaluation.get('evaluation_details', []),
            timestamp=datetime.now()
        )
        
        return decision
    
    def _create_fallback_decision(self, tasks: List[CognitiveTask]) -> ExecutiveDecision:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ±ºå®šã®ä½œæˆ"""
        decision_id = f"fallback_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        # æœ€åˆã®ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ
        first_task = tasks[0] if tasks else None
        task_sequence = [first_task.task_id] if first_task else []
        
        return ExecutiveDecision(
            decision_id=decision_id,
            chosen_strategy=DecisionStrategy.CONSERVATIVE,
            task_sequence=task_sequence,
            resource_allocation={},
            confidence=0.3,
            rationale='Fallback decision due to error',
            alternatives_considered=[],
            timestamp=datetime.now()
        )
    
    async def update_strategy_performance(self, decision_id: str, success: bool, 
                                        performance_metrics: Dict[str, float]):
        """æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ›´æ–°"""
        try:
            # æ±ºå®šå±¥æ­´ã‹ã‚‰è©²å½“æ±ºå®šã‚’æ¤œç´¢
            target_decision = None
            for decision in reversed(self.decision_history):
                if decision.decision_id == decision_id:
                    target_decision = decision
                    break
            
            if target_decision:
                strategy = target_decision.chosen_strategy
                performance_score = 1.0 if success else 0.0
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é‡ã¿ä»˜ãåˆè¨ˆ
                if performance_metrics:
                    weighted_score = (
                        performance_metrics.get('efficiency', 0.5) * 0.3 +
                        performance_metrics.get('quality', 0.5) * 0.4 +
                        performance_metrics.get('user_satisfaction', 0.5) * 0.3
                    )
                    performance_score = (performance_score + weighted_score) / 2.0
                
                self.strategy_performance[strategy].append(performance_score)
                
                logging.debug(f"ğŸ“Š æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°: {strategy.value} -> {performance_score:.2f}")
            
        except Exception as e:
            logging.error(f"âŒ æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_executive_statistics(self) -> Dict[str, Any]:
        """å®Ÿè¡Œåˆ¶å¾¡çµ±è¨ˆ"""
        strategy_stats = {}
        for strategy, performances in self.strategy_performance.items():
            if performances:
                strategy_stats[strategy.value] = {
                    'average_performance': sum(performances) / len(performances),
                    'sample_count': len(performances),
                    'recent_performance': performances[-5:] if len(performances) >= 5 else performances
                }
        
        return {
            'working_memory': self.working_memory.get_current_context(),
            'attention_manager': self.attention_manager.get_attention_statistics(),
            'metacognition': self.meta_cognition.get_metacognitive_statistics(),
            'decision_history_size': len(self.decision_history),
            'strategy_performance': strategy_stats
        }