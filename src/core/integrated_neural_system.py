"""
Integrated Neural System - è„³å‹çµ±åˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
è„³å¹¹ã€å¤§è„³è¾ºç¸ç³»ã€å¤§è„³çš®è³ªã®å”èª¿å‹•ä½œã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…
"""

import asyncio
import logging
import json
import math
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timedelta
from collections import defaultdict, deque

from .neural_kernel import NeuralKernel, SystemStatus
from .emotional_system import EmotionalProcessingSystem, EmotionalContext, ThreatLevel
from .executive_controller import ExecutiveController, CognitiveTask, ExecutiveDecision, DecisionStrategy

class ProcessingMode(Enum):
    """å‡¦ç†ãƒ¢ãƒ¼ãƒ‰"""
    EMERGENCY = "emergency"        # ç·Šæ€¥æ™‚ï¼ˆæ„Ÿæƒ…ç³»ä¸»å°ï¼‰
    ANALYTICAL = "analytical"     # åˆ†æçš„ï¼ˆçš®è³ªä¸»å°ï¼‰
    INTUITIVE = "intuitive"       # ç›´æ„Ÿçš„ï¼ˆçµ±åˆå‡¦ç†ï¼‰
    MAINTENANCE = "maintenance"   # ä¿å®ˆçš„ï¼ˆåŸºç›¤ç³»ä¸»å°ï¼‰

class NeuralIntegrationLevel(Enum):
    """ç¥çµŒçµ±åˆãƒ¬ãƒ™ãƒ«"""
    BASIC = 1      # åŸºæœ¬çš„çµ±åˆ
    MODERATE = 2   # ä¸­ç¨‹åº¦çµ±åˆ
    HIGH = 3       # é«˜åº¦çµ±åˆ
    SEAMLESS = 4   # ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹çµ±åˆ

@dataclass
class NeuralProcessingResult:
    """ç¥çµŒå‡¦ç†çµæœ"""
    goal: str
    processing_mode: ProcessingMode
    integration_level: NeuralIntegrationLevel
    executive_decision: ExecutiveDecision
    emotional_context: EmotionalContext
    system_state: Dict[str, Any]
    performance_metrics: Dict[str, float]
    feedback_loops_active: List[str]
    execution_time: float
    success: bool
    learning_updates: Dict[str, Any]
    timestamp: datetime

class FeedbackLoopType(Enum):
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚¿ã‚¤ãƒ—"""
    IMMEDIATE = "immediate"      # ~100ms (åå°„çš„èª¿æ•´)
    TACTICAL = "tactical"        # ~1-5åˆ† (æˆ¦è¡“çš„èª¿æ•´)
    STRATEGIC = "strategic"      # ~æ™‚é–“/æ—¥ (æˆ¦ç•¥çš„å­¦ç¿’)

@dataclass
class FeedbackLoop:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—"""
    loop_id: str
    loop_type: FeedbackLoopType
    source_system: str
    target_system: str
    feedback_function: str
    update_interval: float  # seconds
    last_update: datetime
    active: bool
    performance_impact: float

class FeedbackLoopManager:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.active_loops: Dict[str, FeedbackLoop] = {}
        self.loop_history = deque(maxlen=1000)
        self.performance_metrics = {
            'total_feedback_cycles': 0,
            'successful_adaptations': 0,
            'system_improvements': 0
        }
        
        # äºˆå®šç¾©ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
        self._initialize_standard_loops()
        
    def _initialize_standard_loops(self):
        """æ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®åˆæœŸåŒ–"""
        standard_loops = [
            # å³åº§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆè„³å¹¹ â†’ è¾ºç¸ç³»ï¼‰
            FeedbackLoop(
                loop_id="neural_to_emotional",
                loop_type=FeedbackLoopType.IMMEDIATE,
                source_system="neural_kernel",
                target_system="emotional_system",
                feedback_function="system_state_to_emotional_state",
                update_interval=0.1,
                last_update=datetime.now(),
                active=True,
                performance_impact=0.8
            ),
            
            # æˆ¦è¡“çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆè¾ºç¸ç³» â†’ çš®è³ªï¼‰
            FeedbackLoop(
                loop_id="emotional_to_executive",
                loop_type=FeedbackLoopType.TACTICAL,
                source_system="emotional_system",
                target_system="executive_controller",
                feedback_function="emotional_context_to_cognitive_bias",
                update_interval=60.0,
                last_update=datetime.now(),
                active=True,
                performance_impact=0.6
            ),
            
            # æˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆå…¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå­¦ç¿’ï¼‰
            FeedbackLoop(
                loop_id="integrated_learning",
                loop_type=FeedbackLoopType.STRATEGIC,
                source_system="integrated_system",
                target_system="all_subsystems",
                feedback_function="holistic_performance_optimization",
                update_interval=3600.0,  # 1æ™‚é–“
                last_update=datetime.now(),
                active=True,
                performance_impact=0.9
            )
        ]
        
        for loop in standard_loops:
            self.active_loops[loop.loop_id] = loop
    
    async def manage_feedback_loops(self, system_components: Dict[str, Any]):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®ç®¡ç†"""
        try:
            current_time = datetime.now()
            
            # å„ãƒ«ãƒ¼ãƒ—ã®æ›´æ–°ãƒã‚§ãƒƒã‚¯
            for loop_id, loop in self.active_loops.items():
                if not loop.active:
                    continue
                
                time_since_update = (current_time - loop.last_update).total_seconds()
                
                if time_since_update >= loop.update_interval:
                    await self._execute_feedback_loop(loop, system_components)
                    loop.last_update = current_time
                    self.performance_metrics['total_feedback_cycles'] += 1
            
        except Exception as e:
            logging.error(f"âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _execute_feedback_loop(self, loop: FeedbackLoop, 
                                   system_components: Dict[str, Any]):
        """å€‹åˆ¥ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ"""
        try:
            if loop.feedback_function == "system_state_to_emotional_state":
                await self._neural_to_emotional_feedback(loop, system_components)
                
            elif loop.feedback_function == "emotional_context_to_cognitive_bias":
                await self._emotional_to_executive_feedback(loop, system_components)
                
            elif loop.feedback_function == "holistic_performance_optimization":
                await self._integrated_learning_feedback(loop, system_components)
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã«è¨˜éŒ²
            feedback_record = {
                'loop_id': loop.loop_id,
                'execution_time': datetime.now(),
                'performance_impact': loop.performance_impact
            }
            self.loop_history.append(feedback_record)
            
        except Exception as e:
            logging.error(f"âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {loop.loop_id} - {e}")
    
    async def _neural_to_emotional_feedback(self, loop: FeedbackLoop, 
                                          system_components: Dict[str, Any]):
        """ç¥çµŒç³»â†’æ„Ÿæƒ…ç³»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        neural_kernel = system_components.get('neural_kernel')
        emotional_system = system_components.get('emotional_system')
        
        if not neural_kernel or not emotional_system:
            return
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®å–å¾—
            system_state = await neural_kernel.get_comprehensive_status()
            
            # ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
            stress_indicators = {
                'cpu_usage': system_state.get('system_health', {}).get('vital_signs', {}).get('cpu_usage', {}).get('value', 0),
                'memory_usage': system_state.get('system_health', {}).get('vital_signs', {}).get('memory_usage', {}).get('value', 0),
                'resource_warnings': len(system_state.get('resources', {}).get('warnings', []))
            }
            
            stress_level = min(
                (stress_indicators['cpu_usage'] / 100.0 +
                 stress_indicators['memory_usage'] / 100.0 +
                 stress_indicators['resource_warnings'] / 5.0) / 3.0,
                1.0
            )
            
            # æ„Ÿæƒ…ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¹ãƒˆãƒ¬ã‚¹çŠ¶æ…‹æ›´æ–°
            if hasattr(emotional_system, 'update_system_stress'):
                await emotional_system.update_system_stress(stress_level)
            
            logging.debug(f"ğŸ”„ ç¥çµŒâ†’æ„Ÿæƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ« {stress_level:.2f}")
            
        except Exception as e:
            logging.error(f"âŒ ç¥çµŒâ†’æ„Ÿæƒ…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _emotional_to_executive_feedback(self, loop: FeedbackLoop, 
                                             system_components: Dict[str, Any]):
        """æ„Ÿæƒ…ç³»â†’å®Ÿè¡Œåˆ¶å¾¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        emotional_system = system_components.get('emotional_system')
        executive_controller = system_components.get('executive_controller')
        
        if not emotional_system or not executive_controller:
            return
        
        try:
            # æ„Ÿæƒ…çŠ¶æ…‹ã®å–å¾—
            emotional_stats = emotional_system.get_emotional_statistics()
            current_state = emotional_stats.get('current_state', 'neutral')
            
            # èªçŸ¥ãƒã‚¤ã‚¢ã‚¹èª¿æ•´
            cognitive_adjustments = {}
            
            if current_state == 'anxious':
                # ä¸å®‰æ™‚ã¯ä¿å®ˆçš„ãƒã‚¤ã‚¢ã‚¹
                cognitive_adjustments['risk_aversion'] = 0.3
                cognitive_adjustments['attention_narrowing'] = 0.2
                
            elif current_state == 'confident':
                # è‡ªä¿¡æ™‚ã¯ç©æ¥µçš„ãƒã‚¤ã‚¢ã‚¹
                cognitive_adjustments['risk_tolerance'] = 0.2
                cognitive_adjustments['attention_broadening'] = 0.1
                
            elif current_state == 'frustrated':
                # ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã¯æ³¨æ„æ•£æ¼«
                cognitive_adjustments['impulsivity'] = 0.3
                cognitive_adjustments['patience_reduction'] = 0.2
            
            # å®Ÿè¡Œåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã¸ã®èª¿æ•´é©ç”¨
            if hasattr(executive_controller, 'apply_emotional_bias'):
                await executive_controller.apply_emotional_bias(cognitive_adjustments)
            
            logging.debug(f"ğŸ”„ æ„Ÿæƒ…â†’å®Ÿè¡Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {current_state} -> {len(cognitive_adjustments)}èª¿æ•´")
            
        except Exception as e:
            logging.error(f"âŒ æ„Ÿæƒ…â†’å®Ÿè¡Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _integrated_learning_feedback(self, loop: FeedbackLoop, 
                                          system_components: Dict[str, Any]):
        """çµ±åˆå­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        try:
            # å…¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’åé›†
            performance_data = {}
            
            for system_name, system in system_components.items():
                if hasattr(system, 'get_performance_statistics'):
                    stats = system.get_performance_statistics()
                    performance_data[system_name] = stats
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã®ç‰¹å®š
            improvement_areas = self._identify_improvement_areas(performance_data)
            
            # ã‚·ã‚¹ãƒ†ãƒ é–“é€£æºã®æœ€é©åŒ–
            await self._optimize_system_integration(improvement_areas, system_components)
            
            self.performance_metrics['system_improvements'] += len(improvement_areas)
            
            logging.info(f"ğŸ”„ çµ±åˆå­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {len(improvement_areas)}é ˜åŸŸã®æ”¹å–„")
            
        except Exception as e:
            logging.error(f"âŒ çµ±åˆå­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _identify_improvement_areas(self, performance_data: Dict[str, Any]) -> List[str]:
        """æ”¹å–„é ˜åŸŸã®ç‰¹å®š"""
        improvement_areas = []
        
        # å„ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤ãƒã‚§ãƒƒã‚¯
        thresholds = {
            'success_rate': 0.8,
            'efficiency': 0.7,
            'response_time': 10.0  # ç§’
        }
        
        for system_name, stats in performance_data.items():
            for metric, threshold in thresholds.items():
                value = stats.get(metric, 1.0)
                
                if metric == 'response_time':
                    if value > threshold:  # å¿œç­”æ™‚é–“ã¯ä½ã„æ–¹ãŒè‰¯ã„
                        improvement_areas.append(f"{system_name}_{metric}")
                else:
                    if value < threshold:  # ãã®ä»–ã¯é«˜ã„æ–¹ãŒè‰¯ã„
                        improvement_areas.append(f"{system_name}_{metric}")
        
        return improvement_areas
    
    async def _optimize_system_integration(self, improvement_areas: List[str], 
                                         system_components: Dict[str, Any]):
        """ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã®æœ€é©åŒ–"""
        # çµ±åˆãƒ¬ãƒ™ãƒ«ã®å‹•çš„èª¿æ•´
        if len(improvement_areas) > 3:
            # å•é¡ŒãŒå¤šã„å ´åˆã¯çµ±åˆãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ã‚‹
            for system in system_components.values():
                if hasattr(system, 'increase_integration_level'):
                    await system.increase_integration_level()
        
        # ç‰¹å®šã®å•é¡Œã«å¯¾ã™ã‚‹å¯¾å‡¦
        for area in improvement_areas:
            if 'response_time' in area:
                # å¿œç­”æ™‚é–“å•é¡Œï¼šä¸¦åˆ—å‡¦ç†ã®å¢—åŠ 
                await self._optimize_parallel_processing(system_components)
            elif 'success_rate' in area:
                # æˆåŠŸç‡å•é¡Œï¼šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®å¼·åŒ–
                await self._strengthen_fallback_mechanisms(system_components)

    async def _optimize_parallel_processing(self, system_components: Dict[str, Any]):
        """ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–"""
        logging.debug("âš¡ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–å®Ÿè¡Œ")
        
    async def _strengthen_fallback_mechanisms(self, system_components: Dict[str, Any]):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®å¼·åŒ–"""
        logging.debug("ğŸ›¡ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å¼·åŒ–å®Ÿè¡Œ")
    
    def get_feedback_statistics(self) -> Dict[str, Any]:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±è¨ˆ"""
        return {
            'active_loops': len([l for l in self.active_loops.values() if l.active]),
            'total_loops': len(self.active_loops),
            'performance_metrics': self.performance_metrics.copy(),
            'loop_types': {
                loop_type.value: len([l for l in self.active_loops.values() 
                                    if l.loop_type == loop_type])
                for loop_type in FeedbackLoopType
            }
        }

class IntegratedNeuralSystem:
    """çµ±åˆç¥çµŒã‚·ã‚¹ãƒ†ãƒ  - è„³å‹çµ±åˆå‡¦ç†"""
    
    def __init__(self):
        # ç¥çµŒç³»ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.neural_kernel = None      # è„³å¹¹ï¼ˆåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ï¼‰
        self.emotional_system = None   # å¤§è„³è¾ºç¸ç³»ï¼ˆæ„Ÿæƒ…ãƒ»è¨˜æ†¶ï¼‰
        self.executive_controller = None  # å¤§è„³çš®è³ªï¼ˆé«˜æ¬¡èªçŸ¥ï¼‰
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ç®¡ç†
        self.feedback_manager = FeedbackLoopManager()
        
        # çµ±åˆå‡¦ç†çŠ¶æ…‹
        self.current_integration_level = NeuralIntegrationLevel.BASIC
        self.processing_history = deque(maxlen=1000)
        
        # å­¦ç¿’ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.learning_metrics = {
            'total_goals_processed': 0,
            'successful_integrations': 0,
            'emergency_activations': 0,
            'adaptation_events': 0
        }
        
        # ç·Šæ€¥æ™‚é–¾å€¤
        self.EMERGENCY_THRESHOLD = ThreatLevel.HIGH
        
    async def initialize_neural_systems(self, neural_kernel, emotional_system, executive_controller):
        """ç¥çµŒç³»ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.neural_kernel = neural_kernel
            self.emotional_system = emotional_system
            self.executive_controller = executive_controller
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®é–‹å§‹
            system_components = {
                'neural_kernel': self.neural_kernel,
                'emotional_system': self.emotional_system,
                'executive_controller': self.executive_controller
            }
            
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
            asyncio.create_task(self._continuous_feedback_management(system_components))
            
            logging.info("ğŸ§  çµ±åˆç¥çµŒã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            logging.error(f"âŒ çµ±åˆç¥çµŒã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def process_goal_neural(self, user_goal: str, context: Dict[str, Any] = None) -> NeuralProcessingResult:
        """è„³å‹çµ±åˆå‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        processing_start_time = datetime.now()
        
        try:
            if context is None:
                context = {}
            
            logging.info(f"ğŸ§  ç¥çµŒçµ±åˆå‡¦ç†é–‹å§‹: {user_goal[:50]}...")
            
            # 1. åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªï¼ˆè„³å¹¹ãƒ¬ãƒ™ãƒ«ï¼‰
            system_state = await self._check_neural_foundation(user_goal)
            
            # 2. æ„Ÿæƒ…çš„ãƒ»è¨˜æ†¶çš„è©•ä¾¡ï¼ˆå¤§è„³è¾ºç¸ç³»ãƒ¬ãƒ™ãƒ«ï¼‰
            emotional_context = await self._evaluate_emotional_limbic(user_goal, context)
            
            # 3. å‡¦ç†ãƒ¢ãƒ¼ãƒ‰æ±ºå®š
            processing_mode = self._determine_processing_mode(system_state, emotional_context)
            
            # 4. çµ±åˆãƒ¬ãƒ™ãƒ«é©å¿œ
            await self._adapt_integration_level(processing_mode, emotional_context)
            
            # 5. é«˜æ¬¡èªçŸ¥å‡¦ç†ã¾ãŸã¯ç·Šæ€¥å‡¦ç†ï¼ˆå¤§è„³çš®è³ªãƒ¬ãƒ™ãƒ«ï¼‰
            executive_decision = await self._execute_cognitive_processing(
                user_goal, emotional_context, processing_mode, context
            )
            
            # 6. å®Ÿè¡Œã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
            execution_result = await self._execute_with_neural_monitoring(
                executive_decision, emotional_context, processing_mode
            )
            
            # 7. å­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            learning_updates = await self._neural_learning_integration(
                user_goal, executive_decision, execution_result, emotional_context
            )
            
            # 8. çµæœã®çµ±åˆ
            processing_result = self._create_processing_result(
                user_goal, processing_mode, executive_decision,
                emotional_context, system_state, execution_result,
                learning_updates, processing_start_time
            )
            
            # å‡¦ç†å±¥æ­´ã«è¨˜éŒ²
            self.processing_history.append(processing_result)
            self.learning_metrics['total_goals_processed'] += 1
            
            if processing_result.success:
                self.learning_metrics['successful_integrations'] += 1
            
            execution_time = (datetime.now() - processing_start_time).total_seconds()
            logging.info(f"ğŸ¯ ç¥çµŒçµ±åˆå‡¦ç†å®Œäº†: {processing_result.success} "
                        f"({execution_time:.2f}ç§’, ãƒ¢ãƒ¼ãƒ‰: {processing_mode.value})")
            
            return processing_result
            
        except Exception as e:
            logging.error(f"âŒ ç¥çµŒçµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_error_result(user_goal, str(e), processing_start_time)
    
    async def _check_neural_foundation(self, user_goal: str) -> Dict[str, Any]:
        """åŸºç›¤ç¥çµŒã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª"""
        try:
            if self.neural_kernel:
                comprehensive_status = await self.neural_kernel.get_comprehensive_status()
                
                # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã®è©•ä¾¡
                system_health = comprehensive_status.get('system_health', {})
                status = system_health.get('status', 'unknown')
                
                return {
                    'health_status': status,
                    'vital_signs': system_health.get('vital_signs', {}),
                    'resources': comprehensive_status.get('resources', {}),
                    'foundation_stable': status in ['healthy', 'warning']
                }
            else:
                return {
                    'health_status': 'unknown',
                    'foundation_stable': False
                }
                
        except Exception as e:
            logging.error(f"âŒ åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return {'foundation_stable': False}
    
    async def _evaluate_emotional_limbic(self, user_goal: str, context: Dict[str, Any]) -> EmotionalContext:
        """æ„Ÿæƒ…çš„ãƒ»è¨˜æ†¶çš„è©•ä¾¡"""
        try:
            if self.emotional_system:
                return await self.emotional_system.evaluate_task_emotion(user_goal)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ„Ÿæƒ…ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                from .emotional_system import EmotionalContext, ThreatLevel, EmotionalState
                return EmotionalContext(
                    threat_level=ThreatLevel.MODERATE,
                    emotional_weight=0.5,
                    confidence=0.3,
                    valence=0.0,
                    arousal=0.5,
                    state=EmotionalState.NEUTRAL,
                    timestamp=datetime.now()
                )
                
        except Exception as e:
            logging.error(f"âŒ æ„Ÿæƒ…è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            from .emotional_system import EmotionalContext, ThreatLevel, EmotionalState
            return EmotionalContext(
                threat_level=ThreatLevel.MODERATE,
                emotional_weight=0.5,
                confidence=0.1,
                valence=0.0,
                arousal=0.5,
                state=EmotionalState.NEUTRAL,
                timestamp=datetime.now()
            )
    
    def _determine_processing_mode(self, system_state: Dict[str, Any], 
                                 emotional_context: EmotionalContext) -> ProcessingMode:
        """å‡¦ç†ãƒ¢ãƒ¼ãƒ‰æ±ºå®š"""
        try:
            # ç·Šæ€¥äº‹æ…‹æ¤œå‡º
            if (emotional_context.threat_level.value >= self.EMERGENCY_THRESHOLD.value or
                not system_state.get('foundation_stable', True)):
                self.learning_metrics['emergency_activations'] += 1
                return ProcessingMode.EMERGENCY
            
            # æ„Ÿæƒ…çŠ¶æ…‹ãƒ»è„…å¨ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹åˆ¤å®š
            if emotional_context.threat_level == ThreatLevel.HIGH:
                return ProcessingMode.EMERGENCY
            elif emotional_context.arousal > 0.6:
                return ProcessingMode.INTUITIVE
            elif emotional_context.confidence > 0.4 or emotional_context.emotional_weight > 0.6:
                return ProcessingMode.ANALYTICAL
            else:
                return ProcessingMode.MAINTENANCE
                
        except Exception as e:
            logging.error(f"âŒ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰æ±ºå®šã‚¨ãƒ©ãƒ¼: {e}")
            return ProcessingMode.MAINTENANCE
    
    async def _adapt_integration_level(self, processing_mode: ProcessingMode, 
                                     emotional_context: EmotionalContext):
        """çµ±åˆãƒ¬ãƒ™ãƒ«ã®é©å¿œ"""
        try:
            target_level = self.current_integration_level
            
            if processing_mode == ProcessingMode.EMERGENCY:
                target_level = NeuralIntegrationLevel.HIGH
            elif processing_mode == ProcessingMode.ANALYTICAL:
                target_level = NeuralIntegrationLevel.SEAMLESS
            elif processing_mode == ProcessingMode.INTUITIVE:
                target_level = NeuralIntegrationLevel.MODERATE
            else:  # MAINTENANCE
                target_level = NeuralIntegrationLevel.BASIC
            
            if target_level != self.current_integration_level:
                self.current_integration_level = target_level
                self.learning_metrics['adaptation_events'] += 1
                logging.debug(f"ğŸ”„ çµ±åˆãƒ¬ãƒ™ãƒ«å¤‰æ›´: {target_level.name}")
                
        except Exception as e:
            logging.error(f"âŒ çµ±åˆãƒ¬ãƒ™ãƒ«é©å¿œã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _execute_cognitive_processing(self, user_goal: str, emotional_context: EmotionalContext,
                                          processing_mode: ProcessingMode, 
                                          context: Dict[str, Any]) -> ExecutiveDecision:
        """èªçŸ¥å‡¦ç†ã®å®Ÿè¡Œ"""
        try:
            if processing_mode == ProcessingMode.EMERGENCY:
                # ç·Šæ€¥æ™‚ã¯æ„Ÿæƒ…ã‚·ã‚¹ãƒ†ãƒ ä¸»å°ã®ç°¡æ˜“åˆ¤æ–­
                return await self._emergency_response_decision(user_goal, emotional_context)
            
            elif self.executive_controller:
                # é€šå¸¸æ™‚ã¯é«˜æ¬¡èªçŸ¥å‡¦ç†
                # ã‚¿ã‚¹ã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
                task_options = await self._generate_task_options(user_goal, emotional_context)
                
                # çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™
                integrated_context = {
                    **context,
                    'processing_mode': processing_mode,
                    'emotional_context': emotional_context,
                    'integration_level': self.current_integration_level
                }
                
                return await self.executive_controller.executive_decision(task_options, integrated_context)
            
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return self._create_fallback_decision(user_goal)
                
        except Exception as e:
            logging.error(f"âŒ èªçŸ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_decision(user_goal)
    
    async def _emergency_response_decision(self, user_goal: str, 
                                         emotional_context: EmotionalContext) -> ExecutiveDecision:
        """ç·Šæ€¥å¿œç­”æ±ºå®š"""
        decision_id = f"emergency_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        return ExecutiveDecision(
            decision_id=decision_id,
            chosen_strategy=DecisionStrategy.CONSERVATIVE,
            task_sequence=[f"emergency_goal_{hash(user_goal) % 10000}"],
            resource_allocation={'emergency_allocation': 50.0},
            confidence=0.6,
            rationale=f'Emergency response due to threat level: {emotional_context.threat_level.name}',
            alternatives_considered=[],
            timestamp=datetime.now()
        )
    
    async def _generate_task_options(self, user_goal: str, 
                                   emotional_context: EmotionalContext) -> List[CognitiveTask]:
        """ã‚¿ã‚¹ã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        try:
            # åŸºæœ¬ã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ
            base_task = CognitiveTask(
                task_id=f"task_{hash(user_goal) % 10000}",
                description=user_goal,
                task_type="general",
                urgency=emotional_context.arousal,
                importance=abs(emotional_context.valence),
                complexity=emotional_context.threat_level.value / 5.0,
                required_attention=50.0 + emotional_context.emotional_weight * 30.0,
                emotional_weight=emotional_context.emotional_weight,
                deadline=None,
                dependencies=[],
                context={'emotional_context': emotional_context}
            )
            
            return [base_task]
            
        except Exception as e:
            logging.error(f"âŒ ã‚¿ã‚¹ã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _create_fallback_decision(self, user_goal: str) -> ExecutiveDecision:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ±ºå®šã®ä½œæˆ"""
        decision_id = f"fallback_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        return ExecutiveDecision(
            decision_id=decision_id,
            chosen_strategy=DecisionStrategy.CONSERVATIVE,
            task_sequence=[f"fallback_goal_{hash(user_goal) % 10000}"],
            resource_allocation={},
            confidence=0.3,
            rationale='Fallback decision due to system limitation',
            alternatives_considered=[],
            timestamp=datetime.now()
        )
    
    async def _execute_with_neural_monitoring(self, executive_decision: ExecutiveDecision,
                                            emotional_context: EmotionalContext,
                                            processing_mode: ProcessingMode) -> Dict[str, Any]:
        """ç¥çµŒç›£è¦–ä»˜ãå®Ÿè¡Œ"""
        try:
            execution_start = datetime.now()
            
            # å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ï¼ˆç°¡ç•¥åŒ–ï¼‰
            await asyncio.sleep(0.1)  # å®Ÿè¡Œæ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            
            execution_time = (datetime.now() - execution_start).total_seconds()
            
            # æˆåŠŸç‡ã®è¨ˆç®—ï¼ˆå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã¨çµ±åˆãƒ¬ãƒ™ãƒ«ã‚’è€ƒæ…®ï¼‰
            base_success = executive_decision.confidence * 0.4
            
            # çµ±åˆãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹ãƒœãƒ¼ãƒŠã‚¹
            integration_bonus = self.current_integration_level.value * 0.15
            
            # å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹èª¿æ•´
            if processing_mode == ProcessingMode.EMERGENCY:
                # ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ã§ã¯å®‰å…¨å‡¦ç†ã«ã‚ˆã‚ŠæˆåŠŸç‡å‘ä¸Š
                mode_adjustment = 0.3
            elif processing_mode == ProcessingMode.ANALYTICAL:
                mode_adjustment = 0.2
            elif processing_mode == ProcessingMode.INTUITIVE:
                mode_adjustment = 0.1
            else:  # MAINTENANCE
                mode_adjustment = 0.2
            
            # è„…å¨ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé©åˆ‡ãªå‡¦ç†ã«ã‚ˆã‚Šè„…å¨ã‚’å›é¿ï¼‰
            if emotional_context.threat_level == ThreatLevel.CRITICAL:
                threat_adjustment = 0.1  # å±é™ºã ãŒé©åˆ‡ãªå‡¦ç†ã§å¯¾å¿œ
            elif emotional_context.threat_level == ThreatLevel.HIGH:
                threat_adjustment = 0.15
            else:
                threat_adjustment = (6 - emotional_context.threat_level.value) * 0.1
            
            success_probability = base_success + integration_bonus + mode_adjustment + threat_adjustment
            success_probability = min(max(success_probability, 0.1), 0.95)  # 10%-95%ã®ç¯„å›²
            
            success = success_probability > 0.5
            
            return {
                'success': success,
                'execution_time': execution_time,
                'quality': success_probability,
                'neural_monitoring_active': True,
                'performance_metrics': {
                    'efficiency': success_probability,
                    'resource_utilization': 0.7,
                    'error_rate': 1.0 - success_probability
                }
            }
            
        except Exception as e:
            logging.error(f"âŒ ç¥çµŒç›£è¦–å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'execution_time': 0.0,
                'error': str(e)
            }
    
    async def _neural_learning_integration(self, user_goal: str, executive_decision: ExecutiveDecision,
                                         execution_result: Dict[str, Any], 
                                         emotional_context: EmotionalContext) -> Dict[str, Any]:
        """ç¥çµŒå­¦ç¿’çµ±åˆ"""
        try:
            learning_updates = {}
            
            # æ„Ÿæƒ…ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            if self.emotional_system:
                await self.emotional_system.process_task_outcome(
                    executive_decision.decision_id,
                    user_goal,
                    "general",
                    execution_result,
                    emotional_context
                )
                learning_updates['emotional_learning'] = True
            
            # å®Ÿè¡Œåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å­¦ç¿’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            if self.executive_controller:
                await self.executive_controller.update_strategy_performance(
                    executive_decision.decision_id,
                    execution_result.get('success', False),
                    execution_result.get('performance_metrics', {})
                )
                learning_updates['executive_learning'] = True
            
            # ç¥çµŒæ¥ç¶šæœ€é©åŒ–
            success_metric = execution_result.get('quality', 0.5 if execution_result.get('success') else 0.1)
            await self.optimize_neural_connections(user_goal, executive_decision, execution_result, success_metric)
            learning_updates['neural_optimization'] = True
            
            return learning_updates
            
        except Exception as e:
            logging.error(f"âŒ ç¥çµŒå­¦ç¿’çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return {'learning_error': str(e)}
    
    def _create_processing_result(self, user_goal: str, processing_mode: ProcessingMode,
                                executive_decision: ExecutiveDecision, emotional_context: EmotionalContext,
                                system_state: Dict[str, Any], execution_result: Dict[str, Any],
                                learning_updates: Dict[str, Any], start_time: datetime) -> NeuralProcessingResult:
        """å‡¦ç†çµæœã®ä½œæˆ"""
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return NeuralProcessingResult(
            goal=user_goal,
            processing_mode=processing_mode,
            integration_level=self.current_integration_level,
            executive_decision=executive_decision,
            emotional_context=emotional_context,
            system_state=system_state,
            performance_metrics=execution_result.get('performance_metrics', {}),
            feedback_loops_active=[loop.loop_id for loop in self.feedback_manager.active_loops.values() if loop.active],
            execution_time=execution_time,
            success=execution_result.get('success', False),
            learning_updates=learning_updates,
            timestamp=datetime.now()
        )
    
    def _create_error_result(self, user_goal: str, error_message: str, 
                           start_time: datetime) -> NeuralProcessingResult:
        """ã‚¨ãƒ©ãƒ¼çµæœã®ä½œæˆ"""
        from .emotional_system import EmotionalContext, ThreatLevel, EmotionalState
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return NeuralProcessingResult(
            goal=user_goal,
            processing_mode=ProcessingMode.MAINTENANCE,
            integration_level=self.current_integration_level,
            executive_decision=self._create_fallback_decision(user_goal),
            emotional_context=EmotionalContext(
                threat_level=ThreatLevel.HIGH,
                emotional_weight=0.8,
                confidence=0.1,
                valence=-0.5,
                arousal=0.7,
                state=EmotionalState.FRUSTRATED,
                timestamp=datetime.now()
            ),
            system_state={'error': error_message},
            performance_metrics={'error_rate': 1.0},
            feedback_loops_active=[],
            execution_time=execution_time,
            success=False,
            learning_updates={'error_learning': error_message},
            timestamp=datetime.now()
        )
    
    async def _continuous_feedback_management(self, system_components: Dict[str, Any]):
        """ç¶™ç¶šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†"""
        try:
            while True:
                await self.feedback_manager.manage_feedback_loops(system_components)
                await asyncio.sleep(1.0)  # 1ç§’é–“éš”
                
        except asyncio.CancelledError:
            logging.debug("ğŸ”„ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†åœæ­¢")
        except Exception as e:
            logging.error(f"âŒ ç¶™ç¶šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_integration_statistics(self) -> Dict[str, Any]:
        """çµ±åˆçµ±è¨ˆã®å–å¾—"""
        return {
            'current_integration_level': self.current_integration_level.name,
            'learning_metrics': self.learning_metrics.copy(),
            'processing_history_size': len(self.processing_history),
            'feedback_statistics': self.feedback_manager.get_feedback_statistics(),
            'recent_processing_modes': [
                result.processing_mode.value 
                for result in list(self.processing_history)[-10:]
            ],
            'success_rate': (
                self.learning_metrics['successful_integrations'] / 
                max(self.learning_metrics['total_goals_processed'], 1)
            )
        }
    
    async def optimize_neural_connections(self, goal: str, decision: ExecutiveDecision, 
                                        result: Dict[str, Any], success_metric: float):
        """ç¥çµŒæ¥ç¶šã®æœ€é©åŒ–"""
        try:
            # æˆåŠŸåº¦ã«åŸºã¥ãæ¥ç¶šå¼·åº¦èª¿æ•´
            if success_metric > 0.8:
                # é«˜ã„æˆåŠŸç‡ï¼šç¾åœ¨ã®çµ±åˆãƒ¬ãƒ™ãƒ«ã‚’å¼·åŒ–
                if self.current_integration_level.value < NeuralIntegrationLevel.SEAMLESS.value:
                    await self._strengthen_integration()
            elif success_metric < 0.3:
                # ä½ã„æˆåŠŸç‡ï¼šçµ±åˆãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
                await self._adjust_integration_for_improvement()
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®åŠ¹ç‡åŒ–
            await self._optimize_feedback_efficiency(success_metric)
            
        except Exception as e:
            logging.error(f"âŒ ç¥çµŒæ¥ç¶šæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _strengthen_integration(self):
        """çµ±åˆå¼·åŒ–"""
        if self.current_integration_level.value < NeuralIntegrationLevel.SEAMLESS.value:
            new_level = NeuralIntegrationLevel(self.current_integration_level.value + 1)
            self.current_integration_level = new_level
            self.learning_metrics['adaptation_events'] += 1
            logging.debug(f"â¬†ï¸ çµ±åˆãƒ¬ãƒ™ãƒ«å¼·åŒ–: {new_level.name}")
    
    async def _adjust_integration_for_improvement(self):
        """æ”¹å–„ã®ãŸã‚ã®çµ±åˆèª¿æ•´"""
        # ã‚ˆã‚Šä¿å®ˆçš„ãªçµ±åˆãƒ¬ãƒ™ãƒ«ã«èª¿æ•´
        if self.current_integration_level.value > NeuralIntegrationLevel.BASIC.value:
            new_level = NeuralIntegrationLevel(self.current_integration_level.value - 1)
            self.current_integration_level = new_level
            self.learning_metrics['adaptation_events'] += 1
            logging.debug(f"â¬‡ï¸ çµ±åˆãƒ¬ãƒ™ãƒ«èª¿æ•´: {new_level.name}")
    
    async def _optimize_feedback_efficiency(self, success_metric: float):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åŠ¹ç‡ã®æœ€é©åŒ–"""
        # æˆåŠŸç‡ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é »åº¦èª¿æ•´
        if success_metric > 0.8:
            # é«˜æˆåŠŸç‡ï¼šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é »åº¦ã‚’ä¸‹ã’ã‚‹
            for loop in self.feedback_manager.active_loops.values():
                if loop.loop_type == FeedbackLoopType.IMMEDIATE:
                    loop.update_interval = min(loop.update_interval * 1.1, 1.0)
        elif success_metric < 0.3:
            # ä½æˆåŠŸç‡ï¼šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é »åº¦ã‚’ä¸Šã’ã‚‹
            for loop in self.feedback_manager.active_loops.values():
                if loop.loop_type == FeedbackLoopType.IMMEDIATE:
                    loop.update_interval = max(loop.update_interval * 0.9, 0.05)