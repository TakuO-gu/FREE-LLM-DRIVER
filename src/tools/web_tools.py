"""
ã‚¦ã‚§ãƒ–ãƒ„ãƒ¼ãƒ«
åŸºæœ¬çš„ãªWebæ¤œç´¢ã¨ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸å–å¾—æ©Ÿèƒ½
"""

import asyncio
import logging
import requests
from typing import Dict, List, Optional, Any
from urllib.parse import quote, urlparse
import json
import re

class WebSearcher:
    """ã‚¦ã‚§ãƒ–æ¤œç´¢ãƒ„ãƒ¼ãƒ«"""
    
    def __init__(self, safe_mode: bool = True):
        self.safe_mode = safe_mode
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
    def search_web(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """ã‚¦ã‚§ãƒ–æ¤œç´¢å®Ÿè¡Œï¼ˆDuckDuckGo Instant Answer APIä½¿ç”¨ï¼‰"""
        try:
            # DuckDuckGo Instant Answer APIï¼ˆç„¡æ–™ï¼‰
            search_url = f"https://api.duckduckgo.com/?q={quote(query)}&format=json&no_html=1&skip_disambig=1"
            
            response = self.session.get(search_url, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            results = []
            
            # Abstractï¼ˆè¦ç´„ï¼‰
            if data.get('Abstract'):
                results.append({
                    'title': data.get('Heading', 'DuckDuckGoçµæœ'),
                    'snippet': data.get('Abstract', ''),
                    'url': data.get('AbstractURL', ''),
                    'source': 'DuckDuckGo'
                })
            
            # Related Topics
            for topic in data.get('RelatedTopics', [])[:max_results-1]:
                if isinstance(topic, dict) and topic.get('Text'):
                    results.append({
                        'title': topic.get('Text', '')[:100] + '...',
                        'snippet': topic.get('Text', ''),
                        'url': topic.get('FirstURL', ''),
                        'source': 'DuckDuckGo'
                    })
            
            # Definition
            if data.get('Definition'):
                results.append({
                    'title': f"å®šç¾©: {data.get('DefinitionWord', '')}",
                    'snippet': data.get('Definition', ''),
                    'url': data.get('DefinitionURL', ''),
                    'source': 'Dictionary'
                })
            
            # Answerï¼ˆç›´æ¥å›ç­”ï¼‰
            if data.get('Answer'):
                results.append({
                    'title': f"å›ç­”: {query}",
                    'snippet': data.get('Answer', ''),
                    'url': '',
                    'source': 'DuckDuckGo Answer'
                })
            
            return results[:max_results]
            
        except Exception as e:
            logging.error(f"âŒ ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return [{'title': 'ã‚¨ãƒ©ãƒ¼', 'snippet': f'æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}', 'url': '', 'source': 'Error'}]
    
    def get_page_content(self, url: str, max_length: int = 2000) -> Dict[str, str]:
        """ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®å†…å®¹å–å¾—"""
        try:
            if not self._is_safe_url(url):
                return {
                    'content': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®ç†ç”±ã§ã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™',
                    'title': 'ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™',
                    'error': 'Unsafe URL'
                }
            
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # ç°¡å˜ãªHTMLè§£æ
            content = response.text
            
            # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
            title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE | re.DOTALL)
            title = title_match.group(1).strip() if title_match else 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—'
            
            # HTMLã‚¿ã‚°ã‚’é™¤å»
            text_content = re.sub(r'<[^>]+>', ' ', content)
            text_content = ' '.join(text_content.split())  # ç©ºç™½æ­£è¦åŒ–
            
            # é•·ã•åˆ¶é™
            if len(text_content) > max_length:
                text_content = text_content[:max_length] + '...'
            
            return {
                'content': text_content,
                'title': title,
                'url': url,
                'length': len(text_content)
            }
            
        except Exception as e:
            logging.error(f"âŒ ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'content': f'ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'title': 'ã‚¨ãƒ©ãƒ¼',
                'error': str(e)
            }
    
    def _is_safe_url(self, url: str) -> bool:
        """URLå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        if not self.safe_mode:
            return True
        
        try:
            parsed = urlparse(url)
            
            # HTTPSã¾ãŸã¯HTTPã®ã¿è¨±å¯
            if parsed.scheme not in ['http', 'https']:
                return False
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ç¦æ­¢
            if parsed.hostname in ['localhost', '127.0.0.1', '0.0.0.0']:
                return False
            
            # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ç¦æ­¢
            if parsed.hostname and (
                parsed.hostname.startswith('192.168.') or
                parsed.hostname.startswith('10.') or
                parsed.hostname.startswith('172.')
            ):
                return False
            
            return True
            
        except Exception:
            return False
    
    def search_and_summarize(self, query: str, llm_manager) -> str:
        """æ¤œç´¢çµæœã‚’LLMã§ã¾ã¨ã‚ã¦è¿”ã™"""
        try:
            # ã‚¦ã‚§ãƒ–æ¤œç´¢å®Ÿè¡Œ
            search_results = self.search_web(query, max_results=3)
            
            if not search_results:
                return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«æ•´ç†
            results_text = f"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}\n\n"
            for i, result in enumerate(search_results, 1):
                results_text += f"{i}. {result['title']}\n"
                results_text += f"   å‡ºå…¸: {result['source']}\n"
                results_text += f"   å†…å®¹: {result['snippet'][:300]}...\n"
                if result['url']:
                    results_text += f"   URL: {result['url']}\n"
                results_text += "\n"
            
            # LLMã§è¦ç´„
            summary_prompt = f"""
ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ã€è³ªå•ã€Œ{query}ã€ã«å¯¾ã™ã‚‹å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{results_text}

è¦ç´„ã¯300æ–‡å­—ä»¥å†…ã§ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚
"""
            
            # éåŒæœŸå®Ÿè¡Œã‚’åŒæœŸçš„ã«å‡¦ç†
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # æ—¢ã«å®Ÿè¡Œä¸­ã®ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹å ´åˆ
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        lambda: asyncio.run(llm_manager.get_completion(summary_prompt, task_type="analysis"))
                    )
                    summary = future.result()
            else:
                summary = asyncio.run(llm_manager.get_completion(summary_prompt, task_type="analysis"))
            
            return f"ğŸ” æ¤œç´¢çµæœã¾ã¨ã‚:\n{summary}\n\nğŸ“š å‚è€ƒãƒªãƒ³ã‚¯:\n" + \
                   "\n".join([f"- {r['title']}: {r['url']}" for r in search_results if r['url']])
            
        except Exception as e:
            logging.error(f"âŒ æ¤œç´¢ãƒ»è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

class SimpleWebAPI:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªWeb APIå‘¼ã³å‡ºã—"""
    
    def __init__(self):
        self.session = requests.Session()
    
    def get_json(self, url: str) -> Dict[str, Any]:
        """JSON APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logging.error(f"âŒ API ã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}
    
    def get_weather_info(self, city: str = "Tokyo") -> str:
        """å¤©æ°—æƒ…å ±å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰"""
        try:
            # OpenWeatherMap ã®ç„¡æ–™APIï¼ˆè¦APIã‚­ãƒ¼ï¼‰ã¾ãŸã¯ä»£æ›¿ã‚µãƒ¼ãƒ“ã‚¹
            # ã“ã“ã§ã¯ç°¡å˜ãªä¾‹ã¨ã—ã¦å›ºå®šå€¤ã‚’è¿”ã™
            return f"â›… {city}ã®ç¾åœ¨ã®å¤©æ°—: æ™´ã‚Œã€æ°—æ¸©: 22Â°Cï¼ˆæ³¨: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¤©æ°—APIã¯æœªè¨­å®šï¼‰"
        except Exception as e:
            return f"å¤©æ°—æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"