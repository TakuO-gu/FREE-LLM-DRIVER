"""
è»½é‡ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ã‚¿ã‚¹ã‚¯ã®çµ±åˆç®¡ç†ã¨åŠ¹ç‡çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta

from .task_planner import EfficientTaskPlanner, Task, TaskType, TaskPriority
from .executor import LocalExecutor, ExecutionResult, ExecutionStatus
from .reflector import SimpleReflector
from ..llm.provider_manager import LLMProviderManager

@dataclass
class WorkflowResult:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœ"""
    goal: str
    total_tasks: int
    completed_tasks: int
    failed_tasks: int
    total_time: float
    results: List[ExecutionResult]
    summary: str = ""
    success: bool = False

class LightweightOrchestrator:
    """è»½é‡ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, llm_manager: LLMProviderManager, config: Dict[str, Any] = None):
        self.llm_manager = llm_manager
        self.config = config or {}
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self.task_planner = EfficientTaskPlanner(llm_manager)
        self.executor = LocalExecutor(llm_manager, safe_mode=self.config.get('safe_mode', True))
        self.reflector = SimpleReflector(llm_manager)
        
        # å®Ÿè¡Œè¨­å®š
        self.max_concurrent_tasks = self.config.get('max_concurrent_tasks', 2)
        self.max_retries = self.config.get('max_retries', 2)
        self.timeout_seconds = self.config.get('timeout_seconds', 300)  # 5åˆ†
        
        # çµ±è¨ˆæƒ…å ±
        self.workflow_history: List[WorkflowResult] = []
    
    async def execute_goal(self, goal: str, context: Dict[str, Any] = None) -> WorkflowResult:
        """ç›®æ¨™ã®å®Ÿè¡Œ"""
        if context is None:
            context = {}
        
        start_time = datetime.now()
        
        try:
            logging.info(f"ğŸ¯ ç›®æ¨™å®Ÿè¡Œé–‹å§‹: {goal}")
            
            # Step 1: ã‚¿ã‚¹ã‚¯åˆ†å‰²
            tasks = await self.task_planner.decompose_goal(goal)
            
            if not tasks:
                return WorkflowResult(
                    goal=goal,
                    total_tasks=0,
                    completed_tasks=0,
                    failed_tasks=0,
                    total_time=0.0,
                    results=[],
                    summary="ã‚¿ã‚¹ã‚¯ã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    success=False
                )
            
            # Step 2: ã‚¿ã‚¹ã‚¯å„ªå…ˆåº¦ä»˜ã‘
            prioritized_tasks = self.task_planner.prioritize_tasks(tasks)
            
            # Step 3: ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
            results = await self._execute_tasks_batch(prioritized_tasks, context)
            
            # Step 4: çµæœè©•ä¾¡
            total_time = (datetime.now() - start_time).total_seconds()
            workflow_result = self._analyze_workflow_results(
                goal, prioritized_tasks, results, total_time
            )
            
            # Step 5: ç°¡æ˜“æŒ¯ã‚Šè¿”ã‚Š
            workflow_result.summary = await self._generate_summary(workflow_result)
            
            # å±¥æ­´ã«è¨˜éŒ²
            self.workflow_history.append(workflow_result)
            
            logging.info(f"âœ… ç›®æ¨™å®Ÿè¡Œå®Œäº†: {goal} ({workflow_result.completed_tasks}/{workflow_result.total_tasks})")
            return workflow_result
            
        except Exception as e:
            logging.error(f"âŒ ç›®æ¨™å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {goal} - {e}")
            
            error_result = WorkflowResult(
                goal=goal,
                total_tasks=0,
                completed_tasks=0,
                failed_tasks=1,
                total_time=(datetime.now() - start_time).total_seconds(),
                results=[],
                summary=f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                success=False
            )
            
            self.workflow_history.append(error_result)
            return error_result
    
    async def _execute_tasks_batch(self, tasks: List[Task], context: Dict[str, Any]) -> List[ExecutionResult]:
        """ãƒãƒƒãƒã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        results = []
        
        # ä¾å­˜é–¢ä¿‚ã®ãªã„ã‚¿ã‚¹ã‚¯ã‚’å…ˆã«å®Ÿè¡Œ
        independent_tasks = [t for t in tasks if not t.dependencies]
        dependent_tasks = [t for t in tasks if t.dependencies]
        
        # ç‹¬ç«‹ã‚¿ã‚¹ã‚¯ã®ä¸¦åˆ—å®Ÿè¡Œ
        if independent_tasks:
            batch_size = min(self.max_concurrent_tasks, len(independent_tasks))
            
            for i in range(0, len(independent_tasks), batch_size):
                batch = independent_tasks[i:i + batch_size]
                
                # ä¸¦åˆ—å®Ÿè¡Œ
                batch_results = await asyncio.gather(
                    *[self.executor.execute_task(task, context) for task in batch],
                    return_exceptions=True
                )
                
                # çµæœã®å‡¦ç†
                for result in batch_results:
                    if isinstance(result, Exception):
                        logging.error(f"âŒ ãƒãƒƒãƒå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {result}")
                    else:
                        results.append(result)
        
        # ä¾å­˜ã‚¿ã‚¹ã‚¯ã®é †æ¬¡å®Ÿè¡Œ
        for task in dependent_tasks:
            # ä¾å­˜ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if self._check_dependencies(task, results):
                result = await self.executor.execute_task(task, context)
                results.append(result)
            else:
                # ä¾å­˜ãŒæº€ãŸã•ã‚Œãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                skip_result = ExecutionResult(
                    task_id=task.id,
                    status=ExecutionStatus.SKIPPED,
                    error="ä¾å­˜é–¢ä¿‚ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã›ã‚“"
                )
                results.append(skip_result)
        
        return results
    
    def _check_dependencies(self, task: Task, completed_results: List[ExecutionResult]) -> bool:
        """ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not task.dependencies:
            return True
        
        completed_task_ids = [r.task_id for r in completed_results if r.status == ExecutionStatus.COMPLETED]
        
        return all(dep in completed_task_ids for dep in task.dependencies)
    
    def _analyze_workflow_results(
        self, 
        goal: str, 
        tasks: List[Task], 
        results: List[ExecutionResult], 
        total_time: float
    ) -> WorkflowResult:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœã®åˆ†æ"""
        
        completed = sum(1 for r in results if r.status == ExecutionStatus.COMPLETED)
        failed = sum(1 for r in results if r.status == ExecutionStatus.FAILED)
        
        success = completed > 0 and failed == 0
        
        return WorkflowResult(
            goal=goal,
            total_tasks=len(tasks),
            completed_tasks=completed,
            failed_tasks=failed,
            total_time=total_time,
            results=results,
            success=success
        )
    
    async def _generate_summary(self, workflow_result: WorkflowResult) -> str:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        if workflow_result.success:
            summary = f"âœ… ç›®æ¨™ã€Œ{workflow_result.goal}ã€ã‚’æ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚"
        else:
            summary = f"âš ï¸ ç›®æ¨™ã€Œ{workflow_result.goal}ã€ã®å®Ÿè¡Œã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        
        summary += f"\n- å®Œäº†ã‚¿ã‚¹ã‚¯: {workflow_result.completed_tasks}/{workflow_result.total_tasks}"
        summary += f"\n- å®Ÿè¡Œæ™‚é–“: {workflow_result.total_time:.1f}ç§’"
        
        if workflow_result.failed_tasks > 0:
            summary += f"\n- å¤±æ•—ã‚¿ã‚¹ã‚¯: {workflow_result.failed_tasks}å€‹"
        
        return summary
    
    async def execute_simple_task(self, description: str, task_type: str = "general") -> str:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã®ç›´æ¥å®Ÿè¡Œ"""
        
        try:
            response = await self.llm_manager.get_completion(
                description,
                task_type=task_type
            )
            
            logging.info(f"âœ… ã‚·ãƒ³ãƒ—ãƒ«ã‚¿ã‚¹ã‚¯å®Œäº†: {description[:50]}...")
            return response
            
        except Exception as e:
            logging.error(f"âŒ ã‚·ãƒ³ãƒ—ãƒ«ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    async def batch_execute_simple_tasks(self, tasks: List[str], task_type: str = "general") -> List[str]:
        """ã‚·ãƒ³ãƒ—ãƒ«ã‚¿ã‚¹ã‚¯ã®ãƒãƒƒãƒå®Ÿè¡Œ"""
        
        results = []
        batch_size = min(self.max_concurrent_tasks, len(tasks))
        
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i + batch_size]
            
            batch_results = await asyncio.gather(
                *[self.execute_simple_task(task, task_type) for task in batch],
                return_exceptions=True
            )
            
            for result in batch_results:
                if isinstance(result, Exception):
                    results.append(f"ã‚¨ãƒ©ãƒ¼: {str(result)}")
                else:
                    results.append(result)
        
        return results
    
    def get_orchestrator_stats(self) -> Dict[str, Any]:
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼çµ±è¨ˆæƒ…å ±"""
        
        if not self.workflow_history:
            return {
                'total_workflows': 0,
                'success_rate': 0,
                'average_execution_time': 0,
                'average_tasks_per_workflow': 0
            }
        
        total_workflows = len(self.workflow_history)
        successful_workflows = sum(1 for w in self.workflow_history if w.success)
        
        avg_time = sum(w.total_time for w in self.workflow_history) / total_workflows
        avg_tasks = sum(w.total_tasks for w in self.workflow_history) / total_workflows
        
        return {
            'total_workflows': total_workflows,
            'successful_workflows': successful_workflows,
            'success_rate': (successful_workflows / total_workflows * 100) if total_workflows > 0 else 0,
            'average_execution_time': round(avg_time, 2),
            'average_tasks_per_workflow': round(avg_tasks, 1),
            'task_planner_stats': self.task_planner.get_planner_stats(),
            'executor_stats': self.executor.get_execution_stats()
        }
    
    def get_recent_workflows(self, limit: int = 5) -> List[WorkflowResult]:
        """æœ€è¿‘ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å±¥æ­´å–å¾—"""
        return self.workflow_history[-limit:]
    
    def clear_history(self):
        """å±¥æ­´ã®ã‚¯ãƒªã‚¢"""
        self.workflow_history.clear()
        self.executor.clear_history()
        logging.info("ğŸ—‘ï¸ ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼å±¥æ­´ã‚’ã‚¯ãƒªã‚¢")
    
    def optimize_orchestrator(self):
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®æœ€é©åŒ–"""
        self.task_planner.optimize_planner()
        logging.info("ğŸ”§ ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’æœ€é©åŒ–")