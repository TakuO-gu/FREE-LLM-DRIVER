"""
è»½é‡åŒ–ã‚¿ã‚¹ã‚¯ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼
åŠ¹ç‡çš„ãªã‚¿ã‚¹ã‚¯åˆ†å‰²ã¨APIä½¿ç”¨é‡å‰Šæ¸›ã‚’å®Ÿç¾
"""

import hashlib
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum

from ..llm.provider_manager import LLMProviderManager
from ..utils.cache_manager import ResponseCache

class TaskType(Enum):
    """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã®å®šç¾©"""
    SIMPLE = "simple"
    COMPLEX = "complex"
    CODE = "code"
    ANALYSIS = "analysis"
    CREATIVE = "creative"
    QUESTION_ANSWER = "qa"
    WEB_SEARCH = "web_search"

class TaskPriority(Enum):
    """ã‚¿ã‚¹ã‚¯å„ªå…ˆåº¦"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class Task:
    """ã‚¿ã‚¹ã‚¯æƒ…å ±"""
    id: str
    description: str
    task_type: TaskType
    priority: TaskPriority
    dependencies: List[str] = None
    estimated_tokens: int = 0
    context: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.dependencies is None:
            self.dependencies = []
        if self.context is None:
            self.context = {}

class EfficientTaskPlanner:
    """åŠ¹ç‡çš„ãªã‚¿ã‚¹ã‚¯ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼"""
    
    def __init__(self, llm_manager: LLMProviderManager):
        self.llm_manager = llm_manager
        self.cache = ResponseCache(max_size=500, ttl_hours=12)
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ï¼‰
        self.decomposition_template = """Goal: {goal}

Break into 3-5 executable tasks:
Task1: [description] | Task2: [description] | Task3: [description]

Focus on concrete, actionable steps."""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ç”¨ã®æ­£è¦è¡¨ç¾
        self.task_pattern = re.compile(r'Task\d+:\s*([^|]+)')
        
    def _classify_goal_type(self, goal: str) -> TaskType:
        """ç›®æ¨™ã®ç¨®é¡ã‚’åˆ†é¡"""
        goal_lower = goal.lower()
        
        # Webæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡º
        search_keywords = [
            'æ¤œç´¢', 'search', 'èª¿ã¹ã‚‹', 'æƒ…å ±', 'æœ€æ–°', 'ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'å¤©æ°—', 
            'ã«ã¤ã„ã¦æ•™ãˆã¦', 'ã¨ã¯', 'ä¾¡æ ¼', 'æ–™é‡‘', 'æ ªä¾¡', 'ç‚ºæ›¿',
            'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ', 'ã‚¦ã‚§ãƒ–', 'web', 'å…¬å¼', 'ã‚µã‚¤ãƒˆ'
        ]
        if any(keyword in goal_lower for keyword in search_keywords):
            return TaskType.WEB_SEARCH
        elif any(keyword in goal_lower for keyword in ['code', 'program', 'script', 'function', 'class']):
            return TaskType.CODE
        elif any(keyword in goal_lower for keyword in ['analyze', 'analysis', 'study', 'research']):
            return TaskType.ANALYSIS
        elif any(keyword in goal_lower for keyword in ['create', 'write', 'design', 'generate']):
            return TaskType.CREATIVE
        elif any(keyword in goal_lower for keyword in ['what', 'how', 'why', 'when', 'where', '?']):
            return TaskType.QUESTION_ANSWER
        elif len(goal.split()) > 20:
            return TaskType.COMPLEX
        else:
            return TaskType.SIMPLE
    
    def _estimate_complexity(self, goal: str) -> int:
        """ç›®æ¨™ã®è¤‡é›‘ã•ã‚’æ¨å®šï¼ˆ1-5ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰"""
        factors = 0
        goal_lower = goal.lower()
        
        # é•·ã•ãƒ™ãƒ¼ã‚¹ã®è¤‡é›‘ã•
        if len(goal.split()) > 30:
            factors += 2
        elif len(goal.split()) > 15:
            factors += 1
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®è¤‡é›‘ã•
        complex_keywords = ['multiple', 'various', 'complex', 'advanced', 'comprehensive', 'detailed']
        factors += sum(1 for keyword in complex_keywords if keyword in goal_lower)
        
        # æŠ€è¡“çš„è¤‡é›‘ã•
        tech_keywords = ['algorithm', 'optimization', 'machine learning', 'database', 'api', 'integration']
        factors += sum(1 for keyword in tech_keywords if keyword in goal_lower)
        
        return min(5, max(1, factors))
    
    def _generate_task_id(self, description: str) -> str:
        """ã‚¿ã‚¹ã‚¯IDã®ç”Ÿæˆ"""
        return hashlib.md5(description.encode('utf-8')).hexdigest()[:8]
    
    async def decompose_goal(self, goal: str, max_tasks: int = 5) -> List[Task]:
        """ç›®æ¨™ã®åŠ¹ç‡çš„åˆ†å‰²"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = f"decompose_{hashlib.md5(goal.encode()).hexdigest()}"
        cached_result = self.cache.get_cached_response(cache_key)
        
        if cached_result:
            logging.info("ğŸ’° ã‚¿ã‚¹ã‚¯åˆ†å‰²çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—")
            return self._parse_cached_tasks(cached_result, goal)
        
        # ç›®æ¨™ã®åˆ†æ
        goal_type = self._classify_goal_type(goal)
        complexity = self._estimate_complexity(goal)
        
        # è¤‡é›‘ã•ã«åŸºã¥ãã‚¿ã‚¹ã‚¯æ•°èª¿æ•´
        if complexity <= 2:
            target_tasks = min(3, max_tasks)
        elif complexity <= 3:
            target_tasks = min(4, max_tasks)
        else:
            target_tasks = max_tasks
        
        # è»½é‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
        prompt = self.decomposition_template.format(goal=goal)
        
        try:
            # LLMå®Ÿè¡Œï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œã—ã¦APIä½¿ç”¨é‡ã‚’å‰Šæ¸›ï¼‰
            response = await self.llm_manager.get_completion(
                prompt, 
                task_type="simple_task"
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            self.cache.cache_response(cache_key, response)
            
            # ã‚¿ã‚¹ã‚¯è§£æ
            tasks = self._parse_llm_response(response, goal, goal_type)
            
            logging.info(f"âœ… ç›®æ¨™ã‚’{len(tasks)}å€‹ã®ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²")
            return tasks[:target_tasks]  # æœ€å¤§ã‚¿ã‚¹ã‚¯æ•°åˆ¶é™
            
        except Exception as e:
            logging.error(f"âŒ ã‚¿ã‚¹ã‚¯åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†å‰²
            return self._fallback_decomposition(goal, goal_type)
    
    def _parse_llm_response(self, response: str, original_goal: str, goal_type: TaskType) -> List[Task]:
        """LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æ"""
        tasks = []
        
        # æ­£è¦è¡¨ç¾ã§ã‚¿ã‚¹ã‚¯ã‚’æŠ½å‡º
        matches = self.task_pattern.findall(response)
        
        if not matches:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã—ãªã„å ´åˆã¯è¡Œåˆ†å‰²ã§è©¦è¡Œ
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            matches = [line for line in lines if any(char.isdigit() for char in line[:5])]
            
            # ãã‚Œã§ã‚‚ãƒãƒƒãƒã—ãªã„å ´åˆã¯ã€ã‚ˆã‚ŠæŸ”è»Ÿãªè§£æ
            if not matches:
                logging.warning("âš ï¸ æ¨™æº–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¿ã‚¹ã‚¯æŠ½å‡ºå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ")
                # æ–‡ã‚’åˆ†å‰²ã—ã¦ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æ‰±ã†
                sentences = [s.strip() for s in response.split('.') if len(s.strip()) > 10]
                matches = sentences[:3]  # æœ€å¤§3ã¤
        
        for i, match in enumerate(matches):
            description = match.strip()
            if not description or len(description) < 10:
                continue
            
            # ã‚¿ã‚¹ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
            task = Task(
                id=self._generate_task_id(description),
                description=description,
                task_type=goal_type,
                priority=TaskPriority.MEDIUM,
                estimated_tokens=len(description.split()) * 2,  # ç°¡æ˜“æ¨å®š
                context={'original_goal': original_goal, 'task_index': i}
            )
            
            tasks.append(task)
        
        # ã‚¿ã‚¹ã‚¯ãŒç©ºã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not tasks:
            logging.warning("âš ï¸ LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã§ã‚¿ã‚¹ã‚¯ãŒ0ä»¶ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ")
            return self._fallback_decomposition(original_goal, goal_type)
        
        return tasks
    
    def _parse_cached_tasks(self, cached_response: str, original_goal: str) -> List[Task]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®è§£æ"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®å¾©å…ƒæ™‚ã¯ç°¡ç•¥åŒ–
        return self._parse_llm_response(cached_response, original_goal, TaskType.SIMPLE)
    
    def _fallback_decomposition(self, goal: str, goal_type: TaskType) -> List[Task]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯åˆ†å‰²"""
        logging.info("ğŸ”„ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯åˆ†å‰²ã‚’å®Ÿè¡Œ")
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†å‰²
        if goal_type == TaskType.CODE:
            tasks_desc = [
                "è¦ä»¶ã‚’åˆ†æã—è¨­è¨ˆã‚’æ±ºå®š",
                "ã‚³ãƒ¼ãƒ‰ã®éª¨æ ¼ã‚’ä½œæˆ", 
                "æ©Ÿèƒ½ã‚’å®Ÿè£…",
                "ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒãƒƒã‚°ã‚’å®Ÿè¡Œ"
            ]
        elif goal_type == TaskType.ANALYSIS:
            tasks_desc = [
                "ãƒ‡ãƒ¼ã‚¿ã‚„æƒ…å ±ã‚’åé›†",
                "ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’åˆ†æ",
                "çµè«–ã‚’ã¾ã¨ã‚ã¦å ±å‘Š"
            ]
        else:
            # æ±ç”¨çš„ãªåˆ†å‰²
            sentences = goal.split('.')
            if len(sentences) > 1:
                tasks_desc = [s.strip() for s in sentences if s.strip()][:4]
            else:
                tasks_desc = [
                    f"{goal}ã®æº–å‚™æ®µéš",
                    f"{goal}ã®å®Ÿè¡Œ",
                    f"{goal}ã®ç¢ºèªã¨å®Œäº†"
                ]
        
        tasks = []
        for i, desc in enumerate(tasks_desc):
            task = Task(
                id=self._generate_task_id(desc),
                description=desc,
                task_type=goal_type,
                priority=TaskPriority.MEDIUM,
                context={'original_goal': goal, 'fallback': True, 'task_index': i}
            )
            tasks.append(task)
        
        return tasks
    
    def prioritize_tasks(self, tasks: List[Task], constraints: Dict[str, Any] = None) -> List[Task]:
        """ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆåº¦ä»˜ã‘"""
        if constraints is None:
            constraints = {}
        
        # ç°¡æ˜“å„ªå…ˆåº¦ç®—å‡º
        for task in tasks:
            priority_score = 0
            
            # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹å„ªå…ˆåº¦
            if task.task_type == TaskType.CODE:
                priority_score += 3
            elif task.task_type == TaskType.ANALYSIS:
                priority_score += 2
            else:
                priority_score += 1
            
            # ä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹å„ªå…ˆåº¦
            if not task.dependencies:
                priority_score += 1  # ä¾å­˜ã®ãªã„ã‚¿ã‚¹ã‚¯ã¯å„ªå…ˆ
            
            # æ¨å®šã‚³ã‚¹ãƒˆã«ã‚ˆã‚‹èª¿æ•´
            if task.estimated_tokens < 100:
                priority_score += 1  # è»½ã„ã‚¿ã‚¹ã‚¯ã¯å„ªå…ˆ
            
            # å„ªå…ˆåº¦è¨­å®š
            if priority_score >= 5:
                task.priority = TaskPriority.CRITICAL
            elif priority_score >= 4:
                task.priority = TaskPriority.HIGH
            elif priority_score >= 3:
                task.priority = TaskPriority.MEDIUM
            else:
                task.priority = TaskPriority.LOW
        
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        return sorted(tasks, key=lambda t: (t.priority.value, -t.estimated_tokens), reverse=True)
    
    def get_planner_stats(self) -> Dict[str, Any]:
        """ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®çµ±è¨ˆæƒ…å ±"""
        return {
            'cache_stats': self.cache.get_cache_stats(),
            'total_decompositions': self.cache.stats['saves'],
            'cache_hit_rate': self.cache.get_cache_stats()['hit_rate_percent']
        }
    
    def optimize_planner(self):
        """ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®æœ€é©åŒ–"""
        self.cache.optimize_cache()
        logging.info("ğŸ”§ ã‚¿ã‚¹ã‚¯ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚’æœ€é©åŒ–")